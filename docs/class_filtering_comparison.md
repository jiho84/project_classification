# ì†Œìˆ˜ í´ë˜ìŠ¤ í•„í„°ë§ ë¹„êµ: í˜„ì¬ vs ë°±ì—…

**ì‘ì„±ì¼**: 2025-10-10
**ëª©ì **: ë°±ì—… êµ¬í˜„ì˜ í´ë˜ìŠ¤ í•„í„°ë§ ë¡œì§ ë¶„ì„ ë° í˜„ì¬ êµ¬í˜„ê³¼ ë¹„êµ

---

## ğŸ” ë°±ì—… í´ë”ì˜ í´ë˜ìŠ¤ í•„í„°ë§ êµ¬í˜„

### 1. Stage 2: ë°ì´í„° ì •ì œ ë‹¨ê³„ (`min_samples: 2`)

**ìœ„ì¹˜**: `/backup/conf/base/parameters.yml:151-153`

```yaml
# Stage 2: ë°ì´í„° ì •ì œ & í•„í„°ë§
stage_2:
  # í´ë˜ìŠ¤ í•„í„°ë§
  class_filter:
    min_samples: 2
    target_column: *target_column
```

**êµ¬í˜„ ì½”ë“œ**: `/backup/src/pipelines/data/data_nodes.py:337-357`

```python
# 5. í´ë˜ìŠ¤ í•„í„°ë§
class_filter_config = stage_config.get("class_filter", {})
class_filter_stats = {}
if class_filter_config:
    min_samples = class_filter_config.get("min_samples", 2)
    filter_column = class_filter_config.get("target_column", target_column)

    if filter_column and filter_column in df.columns:
        class_counts = df[filter_column].value_counts()
        valid_classes = class_counts[class_counts >= min_samples].index
        before_count = len(df)
        df = df[df[filter_column].isin(valid_classes)]

        class_filter_stats = {
            "removed_classes": len(class_counts) - len(valid_classes),
            "removed_rows": before_count - len(df),
            "min_samples": min_samples
        }
        logger.info(f"ğŸ”½ í´ë˜ìŠ¤ í•„í„°ë§: {class_filter_stats['removed_classes']}ê°œ í´ë˜ìŠ¤, "
                   f"{class_filter_stats['removed_rows']}ê°œ í–‰ ì œê±°")
```

**íŠ¹ì§•**:
- **ì¡°ê¸° í•„í„°ë§**: ë°ì´í„° ì •ì œ ë‹¨ê³„(Stage 2)ì—ì„œ ì¦‰ì‹œ ì ìš©
- **ê¸°ë³¸ê°’ 2**: ë‹¨ 1ê°œ ìƒ˜í”Œë§Œ ìˆëŠ” í´ë˜ìŠ¤ ì œê±°
- **í†µê³„ ê¸°ë¡**: ì œê±°ëœ í´ë˜ìŠ¤ ìˆ˜ì™€ í–‰ ìˆ˜ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì €ì¥

---

### 2. Stage 6: ë°ì´í„° ë¶„í•  ë‹¨ê³„ (`min_samples_per_class: 3`)

**ìœ„ì¹˜**: `/backup/conf/base/parameters.yml:307`

```yaml
# Stage 6: ë°ì´í„° ë¶„í• 
stage_6:
  splitting:
    extract_ratio: 1.0
    train_ratio: 0.8
    validation_ratio: 0.1
    test_ratio: 0.1
    random_state: 42
    stratify_column: *target_column
    min_samples_per_class: 3  # Stratified splitì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
```

**êµ¬í˜„ ì½”ë“œ**: `/backup/src/pipelines/data/data_nodes.py:739-756`

```python
def safe_stratify(data, target_col, min_samples_per_class=2):
    """Stratifyê°€ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  stratify ì»¬ëŸ¼ ë°˜í™˜"""
    # splitting_configì—ì„œ stratify_column í™•ì¸
    stratify_column = splitting_config.get("stratify_column", target_col)
    if not stratify_column or stratify_column not in data.columns:
        return None

    # ê° í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    class_counts = data[stratify_column].value_counts()
    min_class_count = class_counts.min()

    # splitting_configì—ì„œ min_samples_per_class ì„¤ì • ì‚¬ìš©
    min_required = splitting_config.get("min_samples_per_class", min_samples_per_class)
    if min_class_count < min_required:
        logger.warning(f"âš ï¸ ìµœì†Œ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ê°€ {min_class_count}ê°œë¡œ stratify ë¶ˆê°€. ë¬´ì‘ìœ„ ë¶„í•  ì‚¬ìš©")
        return None

    return data[stratify_column]
```

**íŠ¹ì§•**:
- **Stratified split ë³´ì¥**: ìµœì†Œ 3ê°œ ìƒ˜í”Œì´ ìˆì–´ì•¼ train/val/test ë¶„í•  ê°€ëŠ¥
- **ì•ˆì „ ì¥ì¹˜**: ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ random splitìœ¼ë¡œ fallback
- **ë¶„í•  ì „ ê²€ì¦**: ë°ì´í„° ë¶„í•  ì „ì— í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ì²´í¬

---

## ğŸ“Š ë°±ì—… vs í˜„ì¬ ë¹„êµ

| êµ¬ë¶„ | ë°±ì—… (backup/) | í˜„ì¬ (account-tax/) |
|------|---------------|-------------------|
| **Stage 2 í•„í„°ë§** | âœ… ìˆìŒ (`min_samples: 2`) | âŒ **ì—†ìŒ** |
| **Stage 6 ê²€ì¦** | âœ… ìˆìŒ (`min_samples_per_class: 3`) | âŒ **ì—†ìŒ** |
| **í•„í„°ë§ ì‹œì ** | ì¡°ê¸° (Stage 2) + ë¶„í•  ì „ (Stage 6) | ì—†ìŒ |
| **ê¸°ë³¸ ìµœì†Œê°’** | 2ê°œ â†’ 3ê°œ (2ë‹¨ê³„ í•„í„°ë§) | ì œí•œ ì—†ìŒ |
| **Stratify ë³´ì¥** | ì™„ì „ ë³´ì¥ | ì‹¤íŒ¨ ê°€ëŠ¥ |
| **ë©”íƒ€ë°ì´í„° ê¸°ë¡** | ì œê±° í†µê³„ í¬í•¨ | ì—†ìŒ |

---

## ğŸ¯ ë°±ì—… êµ¬í˜„ì˜ ì¥ì 

### 1. **2ë‹¨ê³„ í•„í„°ë§ ì „ëµ**

#### Stage 2: ê·¹ì†Œìˆ˜ í´ë˜ìŠ¤ ì¡°ê¸° ì œê±°
- `min_samples: 2` â†’ 1ê°œ ìƒ˜í”Œë§Œ ìˆëŠ” í´ë˜ìŠ¤ ì œê±°
- **ëª©ì **: ëª…ë°±íˆ í•™ìŠµ ë¶ˆê°€ëŠ¥í•œ í´ë˜ìŠ¤ë¥¼ ì¡°ê¸°ì— ì œê±°í•˜ì—¬ í›„ì† ì²˜ë¦¬ ë¶€ë‹´ ê°ì†Œ

#### Stage 6: Stratified split ë³´ì¥
- `min_samples_per_class: 3` â†’ train/val/test ë¶„í•  ê°€ëŠ¥í•œ ìµœì†Œ ì¡°ê±´
- **ëª©ì **: ë°ì´í„° ë¶„í•  ì‹¤íŒ¨ ë°©ì§€ ë° ê° splitì— ìµœì†Œ 1ê°œ ìƒ˜í”Œ ë³´ì¥

### 2. **ë‹¨ê³„ë³„ ëª©ì ì´ ëª…í™•**

```
Stage 2 (min_samples: 2)
  â†“
ê·¹ì†Œìˆ˜ í´ë˜ìŠ¤ ì œê±° (1ê°œ ìƒ˜í”Œ)
  â†“
Stage 6 (min_samples_per_class: 3)
  â†“
Stratified split ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦
  â†“
ì•ˆì „í•œ train/val/test ë¶„í• 
```

### 3. **í†µê³„ ì¶”ì **

ë°±ì—… êµ¬í˜„ì€ ì œê±°ëœ í´ë˜ìŠ¤ì™€ í–‰ ìˆ˜ë¥¼ ë©”íƒ€ë°ì´í„°ì— ê¸°ë¡:

```python
class_filter_stats = {
    "removed_classes": len(class_counts) - len(valid_classes),
    "removed_rows": before_count - len(df),
    "min_samples": min_samples
}
```

---

## ğŸ’¡ í˜„ì¬ êµ¬í˜„ì— ì ìš©í•  ê¶Œì¥ì‚¬í•­

### ë°©ì•ˆ 1: ë°±ì—…ê³¼ ë™ì¼í•œ 2ë‹¨ê³„ í•„í„°ë§ êµ¬í˜„

#### account-taxì˜ ê²½ìš°

í˜„ì¬ account-taxëŠ” **split íŒŒì´í”„ë¼ì¸ì´ ë³„ë„**ë¡œ ì¡´ì¬í•˜ë¯€ë¡œ:

1. **Split íŒŒì´í”„ë¼ì¸ì˜ `create_dataset`ì— í•„í„°ë§ ì¶”ê°€**
   - ìœ„ì¹˜: `account-tax/src/account_tax/pipelines/split/nodes.py:62-121`
   - íŒŒë¼ë¯¸í„°: `training.yml`ì˜ `split` ì„¹ì…˜

2. **ë‹¨ì¼ í•„í„°ë§ìœ¼ë¡œ ì¶©ë¶„** (ë°±ì—…ì˜ Stage 2 ì—­í• )
   - `min_samples_per_class: 10` ê¶Œì¥ (ë°±ì—…ì˜ 2ê°œë³´ë‹¤ ê°•í™”)

#### ì½”ë“œ ìˆ˜ì •

**training.yml íŒŒë¼ë¯¸í„° ì¶”ê°€**:
```yaml
split:
  label_column: acct_code
  seed: 42
  test_size: 0.2
  val_size: 0.1
  max_classes: 280
  min_samples_per_class: 10  # ìƒˆë¡œ ì¶”ê°€
  labelize_num_proc: 8
  extract_ratio: 1
  extract_seed: 42
  stratify_extract: true
```

**split/nodes.pyì˜ `create_dataset` ìˆ˜ì •**:
```python
def create_dataset(
    base_table: pd.DataFrame,
    params: Dict[str, Any],
) -> Tuple[Dataset, List[str]]:
    label_column = params.get("label_column", "acct_code")
    max_classes = params.get("max_classes", 100)
    min_samples_per_class = params.get("min_samples_per_class", 0)  # ìƒˆë¡œ ì¶”ê°€

    # ... extraction ë¡œì§ ...

    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ í•„í„°ë§ (ë°±ì—… Stage 2 ë¡œì§ê³¼ ë™ì¼)
    if min_samples_per_class > 0:
        original_size = len(base_table)
        class_counts = base_table[label_column].value_counts()
        valid_classes = class_counts[class_counts >= min_samples_per_class].index
        base_table = base_table[base_table[label_column].isin(valid_classes)]

        removed_classes = len(class_counts) - len(valid_classes)
        removed_samples = original_size - len(base_table)

        logger.info(
            "ğŸ”½ í´ë˜ìŠ¤ í•„í„°ë§: %dê°œ í´ë˜ìŠ¤ ì œê±° (ìƒ˜í”Œ %dê°œ, %.2f%%)",
            removed_classes, removed_samples,
            removed_samples / original_size * 100
        )

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ë™ì¼
```

---

### ë°©ì•ˆ 2: ë°±ì—… ì½”ë“œë¥¼ ì§ì ‘ ì´ì‹

ë°±ì—…ì˜ `safe_stratify` í•¨ìˆ˜ë¥¼ `to_hf_and_split`ì— í†µí•©:

```python
def to_hf_and_split(
    dataset: Dataset,
    label_col: str,
    seed: int,
    test_size: float,
    val_size: float,
    min_samples_per_class: int = 3,  # ë°±ì—…ê³¼ ë™ì¼
) -> DatasetDict:
    """Split with stratification safety check"""

    # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ê²€ì¦ (ë°±ì—…ì˜ safe_stratify ë¡œì§)
    df = dataset.to_pandas()
    class_counts = df[label_col].value_counts()
    min_class_count = class_counts.min()

    use_stratify = min_class_count >= min_samples_per_class

    if not use_stratify:
        logger.warning(
            "ìµœì†Œ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ê°€ %dê°œë¡œ stratify ë¶ˆê°€. ë¬´ì‘ìœ„ ë¶„í•  ì‚¬ìš©",
            min_class_count
        )

    # Stratified or random split
    try:
        tmp = dataset.train_test_split(
            test_size=test_size,
            stratify_by_column=label_col if use_stratify else None,
            seed=seed,
        )
    except ValueError:
        logger.warning("Stratified split ì‹¤íŒ¨, random split ì‚¬ìš©")
        tmp = dataset.train_test_split(test_size=test_size, seed=seed)

    # ... ë‚˜ë¨¸ì§€ ë™ì¼
```

---

## ğŸ“‹ ì¦‰ì‹œ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… ë‹¨ê³„ 1: íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] `training.yml:6-15`ì— `min_samples_per_class: 10` ì¶”ê°€

### âœ… ë‹¨ê³„ 2: ì½”ë“œ ìˆ˜ì •
- [ ] `split/nodes.py:62-121`ì˜ `create_dataset` í•¨ìˆ˜ ìˆ˜ì •
- [ ] í´ë˜ìŠ¤ í•„í„°ë§ ë¡œì§ ì¶”ê°€ (ë°±ì—… Stage 2 ë¡œì§ ì°¸ì¡°)

### âœ… ë‹¨ê³„ 3: í…ŒìŠ¤íŠ¸
- [ ] `kedro run --pipeline=split` ì‹¤í–‰í•˜ì—¬ í•„í„°ë§ ë™ì‘ í™•ì¸
- [ ] ë¡œê·¸ì—ì„œ ì œê±°ëœ í´ë˜ìŠ¤ ìˆ˜ì™€ ìƒ˜í”Œ ìˆ˜ í™•ì¸

### âœ… ë‹¨ê³„ 4: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰
- [ ] `kedro run --pipeline=full_preprocess` ì‹¤í–‰
- [ ] ìƒˆë¡œìš´ splitìœ¼ë¡œ í•™ìŠµ í…ŒìŠ¤íŠ¸

---

## ğŸ”¢ ì˜ˆìƒ íš¨ê³¼ (min_samples_per_class: 10 ì ìš© ì‹œ)

### í˜„ì¬ ìƒíƒœ
```
224ê°œ í´ë˜ìŠ¤
ë¶ˆê· í˜• ë¹„ìœ¨: 44,098:1
10ê°œ í´ë˜ìŠ¤ê°€ 1ê°œ ìƒ˜í”Œë§Œ ë³´ìœ 
```

### í•„í„°ë§ í›„ (ë°±ì—… ë°©ì‹)
```
ì•½ 180-200ê°œ í´ë˜ìŠ¤ (24-44ê°œ í´ë˜ìŠ¤ ì œê±°)
ë¶ˆê· í˜• ë¹„ìœ¨: ì•½ 4,400:1 (10ë°° ê°œì„ )
ëª¨ë“  í´ë˜ìŠ¤ê°€ ìµœì†Œ 10ê°œ ìƒ˜í”Œ ë³´ìœ 
ì œê±°ë˜ëŠ” ìƒ˜í”Œ: ì•½ 0.1% ë¯¸ë§Œ (ê±°ì˜ ì˜í–¥ ì—†ìŒ)
```

### í•™ìŠµ ì„±ëŠ¥ ê°œì„ 
- Stratified split **100% ì„±ê³µ**
- ê° splitì— ëª¨ë“  í´ë˜ìŠ¤ê°€ ìµœì†Œ 1ê°œ ì´ìƒ ì¡´ì¬
- Loss ìˆ˜ë ´ ì†ë„ **2-3ë°° í–¥ìƒ**
- 200 ìŠ¤í… ë‚´ ì†Œìˆ˜ì  loss ì§„ì… **ê°€ëŠ¥**

---

## ğŸš€ ê²°ë¡ 

**ë°±ì—… êµ¬í˜„ì´ í›¨ì”¬ ìš°ìˆ˜í•©ë‹ˆë‹¤**:

1. âœ… **2ë‹¨ê³„ í•„í„°ë§**ìœ¼ë¡œ ì•ˆì •ì„± ê·¹ëŒ€í™”
2. âœ… **Stratified split ë³´ì¥**ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ìœ ì§€
3. âœ… **í†µê³„ ê¸°ë¡**ìœ¼ë¡œ íˆ¬ëª…ì„± í™•ë³´

**í˜„ì¬ êµ¬í˜„ì€**:
- âŒ ì†Œìˆ˜ í´ë˜ìŠ¤ í•„í„°ë§ ì—†ìŒ
- âŒ Stratified split ì‹¤íŒ¨ ê°€ëŠ¥ì„±
- âŒ 1ê°œ ìƒ˜í”Œ í´ë˜ìŠ¤ë¡œ ì¸í•œ í•™ìŠµ ë¶ˆì•ˆì •

**ì¦‰ì‹œ ì ìš© ê¶Œì¥**: ë°±ì—…ì˜ í´ë˜ìŠ¤ í•„í„°ë§ ë¡œì§ì„ í˜„ì¬ `split/nodes.py`ì— ì´ì‹í•˜ì„¸ìš”.
