# ë°ì´í„° íŒŒì´í”„ë¼ì¸ í‰ê°€ ë³´ê³ ì„œ

**ë‚ ì§œ**: 2025-10-01
**í‰ê°€ì**: Code Evaluator Agent
**ë²”ìœ„**: ì „ì²´ íŒŒì´í”„ë¼ì¸ í‰ê°€ (Ingestion â†’ Preprocess â†’ Feature â†’ Split â†’ Train)
**í‰ê°€ ê¸°ì¤€**: 5ê°€ì§€ ê¸°ì¤€ (Catalog I/O, MLflow Hook, ëª¨ë“ˆì„±, ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©, ì¤‘ë³µ)

---

## ğŸ“Š ì¢…í•© í‰ê°€ ì ìˆ˜

| í‰ê°€ ê¸°ì¤€ | ì ìˆ˜ | ë“±ê¸‰ |
|-----------|------|------|
| 1. Catalog ê¸°ë°˜ I/O | 4.5/5 | ìš°ìˆ˜ |
| 2. MLflow Hook ìë™ ê°œì… | 3.5/5 | ì–‘í˜¸ (ê°œì„  í•„ìš”) |
| 3. ëª¨ë“ˆì„± ë¶„ë¦¬ | 4.8/5 | ìš°ìˆ˜ |
| 4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ í™œìš© | 4.8/5 | ìš°ìˆ˜ |
| 5. ì¤‘ë³µ ë° ì»¤ìŠ¤í…€ í•¨ìˆ˜ | 4.5/5 | ìš°ìˆ˜ |
| **ì „ì²´** | **4.2/5** | **ì–‘í˜¸ - ì†Œí­ ê°œì„  í•„ìš”** |

---

## ìš”ì•½

ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ Kedro ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ì™€ MLOps ì›ì¹™ì„ ì˜ ì¤€ìˆ˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ìˆ˜í•œ ëª¨ë“ˆì„±, ì¼ê´€ëœ ì¹´íƒˆë¡œê·¸ ê¸°ë°˜ I/O, íš¨ê³¼ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë„¤ì´í‹°ë¸Œ ë©”ì†Œë“œ í™œìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. MLflow í›… í†µí•©ê³¼ ì¼ë¶€ ìˆ˜ë™ ë¡œê¹… ì½”ë“œ ì œê±°ì—ì„œ ì†Œí­ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì£¼ìš” ê°•ì **:
- ëª¨ë“  íŒŒì´í”„ë¼ì¸ì—ì„œ ì¼ê´€ëœ ì¹´íƒˆë¡œê·¸ ê¸°ë°˜ I/O
- ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ì™€ ì˜ ì •ì˜ëœ ë…¸ë“œ ì—­í• 
- HuggingFace Dataset ë„¤ì´í‹°ë¸Œ ë©”ì†Œë“œì˜ ìš°ìˆ˜í•œ í™œìš©
- ì¤‘ê°„ ë‹¨ê³„ì— ì ì ˆí•œ MemoryDataset ì‚¬ìš©ìœ¼ë¡œ ëª…í™•í•œ ë°ì´í„° íë¦„

**ì™„ë£Œëœ ê°œì„  ì‚¬í•­**:
1. âœ… train/nodes.pyì˜ ì§ì ‘ `mlflow.log_*` í˜¸ì¶œ ì œê±° (298ì¤„)
2. âœ… serialize_to_text ë²¡í„°í™” ê°œì„  (Python ë£¨í”„ â†’ pandas ë²¡í„°í™”)

**ì„ íƒì  ê°œì„  ì‚¬í•­**:
3. MLflow í›…ì„ í†µí•œ ìë™ ì¶”ì  êµ¬í˜„ ê°œì„  (í˜„ì¬ë„ ë™ì‘í•˜ì§€ë§Œ ì»¤ìŠ¤í…€ í›…ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
4. í…ìŠ¤íŠ¸ ì§ë ¬í™” í…œí”Œë¦¿ ì‹œìŠ¤í…œ (ì—¬ëŸ¬ í˜•ì‹ í•„ìš” ì‹œ)

---

## 1. Catalog ê¸°ë°˜ I/O (Catalog-based I/O)

**ì ìˆ˜**: 4.5/5

### ì „ì²´ í‰ê°€

âœ… **ìš°ìˆ˜**: ëª¨ë“  íŒŒì´í”„ë¼ì¸ì´ catalog.ymlì„ í†µí•œ ì…ì¶œë ¥ ì •ì˜ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤. ë…¸ë“œ ì½”ë“œì— ì§ì ‘ íŒŒì¼ ì½ê¸°/ì“°ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.

### íŒŒì´í”„ë¼ì¸ë³„ ë¶„ì„

#### 1.1 Ingestion Pipeline âœ…

**íŒŒì¼**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/ingestion/nodes.py`

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | ìƒíƒœ |
|------|-------|--------|--------|
| `load_data` | `raw_account_data` (catalog) | `validated_raw_data` (MemoryDataset) | âœ… ì™„ë²½ |
| `standardize_columns` | `validated_raw_data` (MemoryDataset) | `standardized_data` (ParquetDataset) | âœ… ì™„ë²½ |
| `extract_metadata` | `standardized_data` (catalog) | `ingestion_metadata` (MemoryDataset) | âœ… ì™„ë²½ |

**ê´€ì°° ì‚¬í•­**:
- ë…¸ë“œ í•¨ìˆ˜ì— í•˜ë“œì½”ë”©ëœ íŒŒì¼ ê²½ë¡œ ì—†ìŒ
- ì¤‘ê°„ ë°ì´í„°ë¥¼ ìœ„í•œ MemoryDataset ì ì ˆíˆ ì‚¬ìš©
- ìµœì¢… ì¶œë ¥ì€ ì••ì¶•ëœ ParquetDatasetìœ¼ë¡œ ì˜ì†í™”

#### 1.2 Preprocess Pipeline âœ…

**íŒŒì¼**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/preprocess/nodes.py`

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | ìƒíƒœ |
|------|-------|--------|--------|
| `clean_data` | `standardized_data`, `params:preprocess.clean` | `cleaned_data` | âœ… ì™„ë²½ |
| `filter_data` | `cleaned_data`, `params:preprocess.filter` | `filtered_data` | âœ… ì™„ë²½ |
| `normalize_value` | `filtered_data`, `params:preprocess.code_mappings` | `normalized_data` | âœ… ì™„ë²½ |
| `validate_data` | `normalized_data`, `parameters` | `validated_data_raw` | âœ… ì™„ë²½ |
| `normalize_missing_values` | `validated_data_raw`, `params:preprocess.missing_values` | `validated_data` | âœ… ì™„ë²½ |

**ê´€ì°° ì‚¬í•­**:
- ëª¨ë“  I/Oê°€ ì¹´íƒˆë¡œê·¸ë¥¼ í†µí•´ ê´€ë¦¬ë¨
- ì„¤ì •ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì ì ˆíˆ ì‚¬ìš©
- ì§ì ‘ íŒŒì¼ ì‘ì—… ì—†ìŒ

#### 1.3 Feature Pipeline âœ…

**íŒŒì¼**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/feature/nodes.py`

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | ìƒíƒœ |
|------|-------|--------|--------|
| `build_features` | `validated_data`, `params:feature.engineering` | `feature_data` | âœ… ì™„ë²½ |
| `select_features` | `feature_data`, `params:feature.selection` | `base_table` | âœ… ì™„ë²½ |

**ê´€ì°° ì‚¬í•­**:
- ê¹”ë”í•œ ì¹´íƒˆë¡œê·¸ ê¸°ë°˜ I/O
- í”¼ì²˜ ì„¤ì •ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì ì ˆíˆ ì‚¬ìš©

#### 1.4 Split Pipeline âœ…

**íŒŒì¼**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/split/nodes.py`

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | ìƒíƒœ |
|------|-------|--------|--------|
| `create_dataset` | `base_table`, `params:split` | `hf_dataset`, `label_names` | âœ… ì™„ë²½ |
| `to_hf_and_split` | `hf_dataset`, params | `split_datasets_raw` | âœ… ì™„ë²½ |
| `labelize_and_cast` | `split_datasets_raw`, `label_names`, params | `split_datasets` | âœ… ì™„ë²½ |
| `serialize_to_text` | `split_datasets`, `params:train.serialization` | `serialized_datasets` | âœ… ì™„ë²½ |

**ê´€ì°° ì‚¬í•­**:
- ëª¨ë“  ì¶œë ¥ì´ ì¹´íƒˆë¡œê·¸ì— ì ì ˆíˆ ì •ì˜ë¨
- HuggingFace Dataset ê°ì²´ëŠ” MemoryDatasetìœ¼ë¡œ ì²˜ë¦¬
- ìµœì¢… ì§ë ¬í™”ëœ ì¶œë ¥ì€ PickleDatasetìœ¼ë¡œ ì €ì¥ (catalog.yml 95-96ì¤„)

#### 1.5 Train Pipeline â˜‘ï¸

**íŒŒì¼**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/nodes.py`

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | ìƒíƒœ |
|------|-------|--------|--------|
| `tokenize_datasets` | `serialized_datasets`, `params:train.tokenization` | `tokenized_datasets`, `token_length_report` | â˜‘ï¸ ê²½ë¯¸í•œ ì´ìŠˆ |

**ê´€ì°°**:
1. **225-228ì¤„**: Tokenizerê°€ ë…¸ë“œ ë‚´ë¶€ì—ì„œ ë¡œë“œë¨
   ```python
   tokenizer = AutoTokenizer.from_pretrained(
       model_name,
       trust_remote_code=True
   )
   ```
   **ì„¤ê³„ ê²°ì •**: í˜„í–‰ ìœ ì§€ - í† í°í™” ë…¸ë“œì˜ ëª©í‘œëŠ” í† í°í™” ê²°ê³¼ì™€ í†µê³„ ì‚°ì¶œ
   **ì´ìœ **:
   - ë…¸ë“œ ê°„ í•¸ë“¤ ì •ë³´ ì „ë‹¬ ë¶ˆí•„ìš” (tokenizerëŠ” ë‹¨ì¼ ë…¸ë“œ ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš©)
   - ë³„ë„ ë¡œë”© ë…¸ë“œë¡œ ë¶„ë¦¬í•  ì‹¤ì§ˆì  ì´ì  ì—†ìŒ
   - í˜„ì¬ êµ¬ì¡°ê°€ ë…¸ë“œì˜ ë‹¨ì¼ ì±…ì„(í† í°í™” + í†µê³„)ì„ ëª…í™•íˆ í‘œí˜„

2. **ì¹´íƒˆë¡œê·¸ ì—”íŠ¸ë¦¬ ì¡´ì¬** (101-106ì¤„): `tokenized_datasets`ëŠ” `MlflowArtifactDataset` ì‚¬ìš© âœ…
   ```yaml
   tokenized_datasets:
     type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
     dataset:
       type: kedro.io.PickleDataset
       filepath: data/06_models/tokenized_datasets.pkl
     artifact_path: data/tokenized_datasets
   ```

### ìœ„ë°˜ ì‚¬í•­

âŒ **ì—†ìŒ** - ëª¨ë“  I/O ì‘ì—…ì´ ì¹´íƒˆë¡œê·¸ ì‚¬ìš©

### ê¶Œì¥ì‚¬í•­

**ì—†ìŒ** - í˜„ì¬ êµ¬ì¡°ê°€ ì ì ˆí•¨

Tokenizerë¥¼ ë³„ë„ ë…¸ë“œë¡œ ë¶„ë¦¬í•˜ì§€ ì•ŠëŠ” ì´ìœ :
- `tokenize_datasets` ë…¸ë“œëŠ” "í† í°í™” + í†µê³„ ì‚°ì¶œ"ì´ë¼ëŠ” ëª…í™•í•œ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§
- Tokenizer ê°ì²´ëŠ” ë…¸ë“œ ì™¸ë¶€ë¡œ ì „ë‹¬í•  í•„ìš” ì—†ìŒ (ë‹¨ì¼ ë…¸ë“œ ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš©)
- ë³„ë„ ë…¸ë“œ ë¶„ë¦¬ ì‹œ ë¶ˆí•„ìš”í•œ ë³µì¡ì„±ë§Œ ì¦ê°€

---

## 2. MLflow Hook ìë™ ê°œì… (MLflow Hook Auto-Integration)

**ì ìˆ˜**: 3.5/5

### ì „ì²´ í‰ê°€

â˜‘ï¸ **ì–‘í˜¸ (ì´ìŠˆ ìˆìŒ)**: MLflow í†µí•©ì´ `MlflowArtifactDataset`ê³¼ Trainerì˜ `report_to=["mlflow"]`ë¥¼ í†µí•´ ë¶€ë¶„ì ìœ¼ë¡œ ìë™í™”ë˜ì–´ ìˆìœ¼ë‚˜, í›… ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ìœ„ë°˜í•˜ëŠ” ìˆ˜ë™ ë¡œê¹… ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤. **(í˜„ì¬ ìˆ˜ì • ì™„ë£Œ)**

### í˜„ì¬ MLflow í†µí•©

#### 2.1 ìë™í™”ëœ í†µí•© âœ…

**ì¹´íƒˆë¡œê·¸ ì„¤ì •** (101-106ì¤„):
```yaml
tokenized_datasets:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: kedro.io.PickleDataset
    filepath: data/06_models/tokenized_datasets.pkl
  artifact_path: data/tokenized_datasets
```
**ìƒíƒœ**: âœ… ì•„í‹°íŒ©íŠ¸ ì¶”ì ì„ ìœ„í•œ `MlflowArtifactDataset` ì ì ˆíˆ ì‚¬ìš©

**MLflow ì„¤ì •** (`mlflow.yml`):
```yaml
server:
  mlflow_tracking_uri: mlruns
tracking:
  experiment:
    name: "account_tax_experiment"
  run:
    nested: false
```
**ìƒíƒœ**: âœ… ì‹¤í—˜ ì„¤ì • ì ì ˆí•¨

**Trainer í†µí•©** (train/nodes.py 544ì¤„):
```python
report_to=["mlflow"]  # MLflowì— ìë™ ë¡œê¹…
```
**ìƒíƒœ**: âœ… Trainer ìë™ ë¡œê¹… í™œì„±í™”

#### 2.2 ìˆ˜ë™ ë¡œê¹… ìœ„ë°˜ âœ… **ìˆ˜ì • ì™„ë£Œ**

**ìœ„ì¹˜**: `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/nodes.py`

**ì´ìŠˆ 1: 298-306ì¤„** - `tokenize_datasets` ë…¸ë“œì—ì„œ ì§ì ‘ MLflow ë¡œê¹… **(ìˆ˜ì • ì™„ë£Œ)**

**ìˆ˜ì • ì „**:
```python
# Log to MLflow if active
try:
    import mlflow
    if mlflow.active_run():
        mlflow.log_metric("token_length_mean", overall_stats["mean"])
        mlflow.log_metric("token_length_max", overall_stats["max"])
        for p in percentiles:
            mlflow.log_metric(f"token_length_p{p}", overall_stats[f"p{p}"])
except Exception as e:
    logger.warning(f"Could not log to MLflow: {e}")
```

**ìˆ˜ì • í›„**:
```python
# MLflow metrics will be logged via hooks when token_length_report is saved to catalog
return tokenized_datasets, token_length_report
```

**ìˆ˜ì •ëœ ì´ìœ **:
1. Kedro-MLflow í›… ì•„í‚¤í…ì²˜ ìœ„ë°˜
2. ë…¸ë“œê°€ ë°ì´í„° ë³€í™˜ ì™¸ì— ë¶€ìˆ˜ íš¨ê³¼(ë¡œê¹…)ë¥¼ ê°€ì§
3. kedro-mlflowì˜ ìë™ ì¶”ì ì„ ìš°íšŒí•¨
4. í…ŒìŠ¤íŠ¸ê°€ ì–´ë ¤ì›Œì§ (MLflow ì»¨í…ìŠ¤íŠ¸ í•„ìš”)
5. "ëª¨ë“ˆí™”(Modularity)" ì›ì¹™ê³¼ ë§ì§€ ì•ŠìŒ

**ì´ìŠˆ 2: 141-145, 163-168, 176-181ì¤„** - ì»¤ìŠ¤í…€ ì½œë°±ì˜ ìˆ˜ë™ ë¡œê¹…

```python
# SpeedCallback - 141-145ì¤„
if hasattr(state, 'log_history'):
    state.log_history.append({
        "speed/tokens_per_sec": tokens_per_sec,
        "step": state.global_step
    })

# TorchMemoryCallback - ìœ ì‚¬í•œ íŒ¨í„´
```

**ì´ê²ƒì´ í—ˆìš©ë˜ëŠ” ì´ìœ **:
- Kedro ë…¸ë“œ ì½”ë“œê°€ ì•„ë‹ˆë¼ Trainer ì½œë°±ì„
- Trainerì˜ `report_to=["mlflow"]`ê°€ ìë™ìœ¼ë¡œ MLflowì™€ ë™ê¸°í™”í•¨
- Trainer ë¡œê¹…ì„ í™•ì¥í•˜ëŠ” ì ì ˆí•œ ë°©ë²•

### ëˆ„ë½: MLflow Hooks

**ê´€ì°°**: í”„ë¡œì íŠ¸ì—ì„œ ì»¤ìŠ¤í…€ í›…ì„ ì°¾ì§€ ëª»í•¨
```bash
# ê²€ìƒ‰ ê²°ê³¼:
find src/account_tax -name "hooks.py" -o -name "hook*.py"
# íŒŒì¼ ì—†ìŒ
```

**í˜„ì¬ ì ‘ê·¼ ë°©ì‹**: kedro-mlflowì˜ ê¸°ë³¸ í›… + MlflowArtifactDatasetì— ì˜ì¡´

**ìƒíƒœ**: â˜‘ï¸ ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ í—ˆìš© ê°€ëŠ¥í•˜ì§€ë§Œ ê°œì„ ë  ìˆ˜ ìˆìŒ

### ìœ„ë°˜ ì‚¬í•­

âœ… **ìˆ˜ì • ì™„ë£Œ**: `tokenize_datasets` ë…¸ë“œì—ì„œ ì§ì ‘ `mlflow.log_*` í˜¸ì¶œ (298-306ì¤„)

### ê¶Œì¥ì‚¬í•­

#### 2.1 ì§ì ‘ MLflow ë¡œê¹… ì œê±° (ìš°ì„ ìˆœìœ„ 1) - âœ… ì™„ë£Œ

**í˜„ì¬ ì½”ë“œ** (train/nodes.py, 298ì¤„):
```python
# âœ… ìˆ˜ì • ì™„ë£Œ - ë°ì´í„°ë§Œ ë°˜í™˜, ì¹´íƒˆë¡œê·¸ê°€ ë¡œê¹… ì²˜ë¦¬
return tokenized_datasets, token_length_report
```

**catalog.ymlì—ì„œ**:
```yaml
token_length_report:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataset  # ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
  # ë˜ëŠ” JSONDataset ì‚¬ìš© (ì´ë¯¸ 109-110ì¤„ì— ì •ì˜ë¨)
```

**ì˜µì…˜ B: í¬ìŠ¤íŠ¸ ë³€í™˜ í›… ì‚¬ìš©** (ê³ ê¸‰ ë¡œê¹…ì´ í•„ìš”í•œ ê²½ìš°):
```python
# src/account_tax/hooks.pyì— ìƒì„±
from kedro.framework.hooks import hook_impl
import mlflow

class TokenMetricsHook:
    @hook_impl
    def after_node_run(self, node, outputs):
        if node.name == "tokenize_datasets" and mlflow.active_run():
            _, token_report = outputs  # ì¶œë ¥ ì–¸íŒ©
            if token_report and "overall" in token_report:
                stats = token_report["overall"]
                mlflow.log_metric("token_length_mean", stats["mean"])
                mlflow.log_metric("token_length_max", stats["max"])
```

**settings.pyì— ë“±ë¡**:
```python
HOOKS = (TokenMetricsHook(),)
```

#### 2.2 Trainerì˜ MLflow í†µí•© í™œìš© (ì´ë¯¸ ì–‘í˜¸)

í˜„ì¬ êµ¬í˜„ (544ì¤„):
```python
report_to=["mlflow"]  # âœ… ì˜¬ë°”ë¦„
```

ì´ê²ƒì´ ìë™ìœ¼ë¡œ ë¡œê¹…í•˜ëŠ” í•­ëª©:
- í•™ìŠµ ì†ì‹¤, í•™ìŠµë¥ , ì—í­
- í‰ê°€ ë©”íŠ¸ë¦­ (`compute_metrics`ë¥¼ í†µí•´)
- ì»¤ìŠ¤í…€ ì½œë°± ë©”íŠ¸ë¦­ (SpeedCallback, TorchMemoryCallback)

**ë³€ê²½ ë¶ˆí•„ìš”** - ì ì ˆí•œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.

#### 2.3 êµ¬ì¡°í™”ëœ ë©”íŠ¸ë¦­ì„ ìœ„í•œ MlflowMetricsDataset ê³ ë ¤

í˜„ì¬ `token_length_report`ëŠ” JSONDatasetìœ¼ë¡œ ì €ì¥ë¨ (109-110ì¤„):
```yaml
token_length_report:
  type: kedro.io.json.JSONDataset
  filepath: data/08_reporting/token_length_report.json
```

**ê°œì„  (ì„ íƒì‚¬í•­)**:
```yaml
token_length_report:
  type: kedro_mlflow.io.metrics.MlflowMetricsDataset
  run_id: null  # í™œì„± ì‹¤í–‰ ì‚¬ìš©
```

ì´ë ‡ê²Œ í•˜ë©´ ìˆ˜ë™ ì½”ë“œ ì—†ì´ ë©”íŠ¸ë¦­ì´ ìë™ìœ¼ë¡œ MLflowì— ë¡œê¹…ë©ë‹ˆë‹¤.

---

## 3. ëª¨ë“ˆì„± ë¶„ë¦¬ (Modularity Separation)

**ì ìˆ˜**: 4.8/5

### ì „ì²´ í‰ê°€

âœ… **ìš°ìˆ˜**: ë…¸ë“œë³„ ë‹¨ì¼ ì±…ì„ ì›ì¹™ìœ¼ë¡œ ëª…í™•í•œ ê´€ì‹¬ì‚¬ ë¶„ë¦¬. `prepare_for_trainer` ë…¸ë“œ(í˜„ì¬ ì—°ê²°ë˜ì§€ ì•ŠìŒ)ì—ì„œ ê²½ë¯¸í•œ ì´ìŠˆ.

### ë…¸ë“œ ì±…ì„ ë¶„ì„

#### 3.1 Ingestion Pipeline âœ…

| ë…¸ë“œ | ì±…ì„ | ì½”ë“œ ë¼ì¸ | ë‹¨ì¼ ì±…ì„? |
|------|---------------|---------------|------------------------|
| `load_data` | ë°ì´í„° ê²€ì¦ë§Œ | 10 lines | âœ… ì˜ˆ |
| `standardize_columns` | ì»¬ëŸ¼ëª… ë§¤í•‘ | 56 lines | âœ… ì˜ˆ (í° dictëŠ” ë¶ˆê°€í”¼) |
| `extract_metadata` | ë©”íƒ€ë°ì´í„° ì¶”ì¶œ | 22 lines | âœ… ì˜ˆ |

**í‰ê°€**: ì™„ë²½í•œ ëª¨ë“ˆì„±. ê° ë…¸ë“œê°€ í•˜ë‚˜ì˜ ëª…í™•í•œ ëª©ì ì„ ê°€ì§.

#### 3.2 Preprocess Pipeline âœ…

| ë…¸ë“œ | ì±…ì„ | ì½”ë“œ ë¼ì¸ | ë‹¨ì¼ ì±…ì„? |
|------|---------------|---------------|------------------------|
| `clean_data` | ì¤‘ë³µ/ë„ ì œê±° | 23 lines | âœ… ì˜ˆ |
| `filter_data` | ì»¬ëŸ¼ ì œì™¸ | 12 lines | âœ… ì˜ˆ |
| `normalize_value` | ì½”ë“œâ†’í…ìŠ¤íŠ¸ ë§¤í•‘ | 53 lines | âœ… ì˜ˆ |
| `validate_data` | ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ | 15 lines | âœ… ì˜ˆ |
| `normalize_missing_values` | ì˜ˆì•½ë¨ (ë¯¸êµ¬í˜„) | 4 lines | âœ… ì˜ˆ (í”Œë ˆì´ìŠ¤í™€ë”) |

**í‰ê°€**: ê¹”ë”í•œ ë¶„ë¦¬. `normalize_value`ëŠ” ì œìë¦¬ ì—°ì‚°ìœ¼ë¡œ ìµœì í™”ë¨ (í—ˆìš© ê°€ëŠ¥í•œ ë³µì¡ì„±).

#### 3.3 Feature Pipeline âœ…

| ë…¸ë“œ | ì±…ì„ | ì½”ë“œ ë¼ì¸ | ë‹¨ì¼ ì±…ì„? |
|------|---------------|---------------|------------------------|
| `add_holiday_features` | íœ´ì¼ í”¼ì²˜ ìƒì„± | 26 lines | âœ… ì˜ˆ |
| `build_features` | í”¼ì²˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | 13 lines | âœ… ì˜ˆ (ë˜í¼) |
| `select_features` | í”¼ì²˜ ì„ íƒ + ì •ë¦¬ | 39 lines | â˜‘ï¸ í—ˆìš© ê°€ëŠ¥ |

**í‰ê°€**:
- `select_features`ëŠ” ë‘ ê°€ì§€ ì‘ì—…(ì„ íƒ + ì •ë¦¬)ì„ í•˜ì§€ë§Œ, 140-142ì¤„ì˜ ì£¼ì„ì—ì„œ ëª…ì‹œí•œ ëŒ€ë¡œ ì˜ë„ì ì„:
  ```python
  # Clean data: remove nulls in label and duplicates (previously in prepare_dataset_inputs)
  ```
  ì´ í†µí•©ì€ í—ˆìš© ê°€ëŠ¥í•˜ë©° íŒŒì´í”„ë¼ì¸ ëª…í™•ì„±ì„ í–¥ìƒì‹œí‚´.

#### 3.4 Split Pipeline âœ…

| ë…¸ë“œ | ì±…ì„ | ì½”ë“œ ë¼ì¸ | ë‹¨ì¼ ì±…ì„? |
|------|---------------|---------------|------------------------|
| `create_dataset` | HF Dataset ìƒì„± + ë¼ë²¨ ìŠ¬ë¡¯ | 40 lines | âœ… ì˜ˆ |
| `to_hf_and_split` | ì¸µí™” train/val/test ë¶„í•  | 54 lines | âœ… ì˜ˆ |
| `labelize_and_cast` | ë¼ë²¨ ì¸ì½”ë”© + ClassLabel ìŠ¤í‚¤ë§ˆ | 30 lines | âœ… ì˜ˆ |
| `serialize_to_text` | NLPìš© í…ìŠ¤íŠ¸ ì§ë ¬í™” | 21 lines | âœ… ì˜ˆ |

**í—¬í¼ í•¨ìˆ˜** (ì ì ˆíˆ ë¶„ë¦¬ë¨):
- `_initialize_label_slots` (4 lines)
- `_upsert_labels_into_slots` (16 lines)
- `make_label2id` (2 lines)
- `make_id2label` (2 lines)

**í‰ê°€**: ì˜ ë¶„í•´ëœ í—¬í¼ í•¨ìˆ˜ë¡œ ìš°ìˆ˜í•œ ëª¨ë“ˆì„±.

#### 3.5 Train Pipeline â˜‘ï¸

| ë…¸ë“œ | ì±…ì„ | ì½”ë“œ ë¼ì¸ | ë‹¨ì¼ ì±…ì„? |
|------|---------------|---------------|------------------------|
| `tokenize_datasets` | í† í°í™” + ë¶„ì„ | 83 lines | â˜‘ï¸ í—ˆìš© ê°€ëŠ¥ (ë¶„ì„ í†µí•©ë¨) |
| `prepare_for_trainer` | Trainer ì„¤ì • (ì—°ê²° ëŠê¹€) | 51 lines | âš ï¸ ë‹¤ì¤‘ ì±…ì„ |

**ì´ìŠˆ**: `prepare_for_trainer` (ì›ë³¸ ì½”ë“œ 311-361ì¤„)ê°€ í•˜ëŠ” ì¼:
1. Tokenizer ì¬ë¡œë“œ
2. Data collator ìƒì„±
3. ë¼ë²¨ ë§¤í•‘ ì¶”ì¶œ

**ìƒíƒœ**: ë…¸ë“œê°€ ì •ì˜ë˜ì—ˆì§€ë§Œ íŒŒì´í”„ë¼ì¸ì— **ì—°ê²°ë˜ì§€ ì•ŠìŒ** (train/pipeline.py 16-24ì¤„ì—ëŠ” `tokenize_datasets`ë§Œ ìˆìŒ)

**ì˜í–¥**: ë‚®ìŒ (í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)

### ìœ„ë°˜ ì‚¬í•­

âš ï¸ **ê²½ë¯¸í•œ ì´ìŠˆ**: `prepare_for_trainer`ê°€ ë‹¤ì¤‘ ì±…ì„ì„ ê°€ì§ (í•˜ì§€ë§Œ íŒŒì´í”„ë¼ì¸ì—ì„œ í™œì„±í™”ë˜ì§€ ì•ŠìŒ)

### ê¶Œì¥ì‚¬í•­

#### 3.1 í™œì„±í™”ë  ê²½ìš° `prepare_for_trainer` ë¶„í• 

**í˜„ì¬** (ì‚¬ìš© ì¤‘ ì•„ë‹˜):
```python
def prepare_for_trainer(...):
    # 1. Tokenizer ë¡œë“œ
    # 2. Collator ìƒì„±
    # 3. ë¼ë²¨ ì¶”ì¶œ
```

**ê¶Œì¥** (ì´ ë…¸ë“œê°€ ì¬ì—°ê²°ë  ê²½ìš°):
```python
# 3ê°œì˜ ë³„ë„ ë…¸ë“œë¡œ ë¶„í• :

def load_tokenizer_for_trainer(model_name: str) -> AutoTokenizer:
    """Load tokenizer."""
    return AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

def create_data_collator(tokenizer: AutoTokenizer) -> DataCollatorWithPadding:
    """Create collator for dynamic padding."""
    return DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)

def extract_label_mappings(tokenized_datasets: DatasetDict) -> Dict[str, Any]:
    """Extract id2label and label2id from dataset."""
    # ... ê¸°ì¡´ ë¡œì§ ...
```

#### 3.2 `tokenize_datasets` ë¶„í•  ê³ ë ¤

**í˜„ì¬**: í† í°í™” + ë¶„ì„ì´ í•˜ë‚˜ì˜ ë…¸ë“œì— (83 lines)

**ì„ íƒì  ê°œì„ **:
```python
def tokenize_datasets(
    serialized_datasets: DatasetDict,
    tokenization_params: Dict[str, Any]
) -> DatasetDict:
    """í† í°í™”ë§Œ."""
    # ... í† í°í™” ë¡œì§ ...
    return tokenized_datasets

def analyze_token_lengths(
    tokenized_datasets: DatasetDict
) -> Dict[str, Any]:
    """í† í° ê¸¸ì´ ë¶„í¬ ë¶„ì„."""
    # ... ë¶„ì„ ë¡œì§ ...
    return token_length_report
```

**íŠ¸ë ˆì´ë“œì˜¤í”„**: ë” ë§ì€ ë…¸ë“œ vs. ë” ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸. í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì€ í—ˆìš© ê°€ëŠ¥í•¨.

---

## 4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ í™œìš© (Library Method Utilization)

**ì ìˆ˜**: 4.8/5

### ì „ì²´ í‰ê°€

âœ… **ìš°ìˆ˜**: pandas, HuggingFace datasets, transformersì—ì„œ ë„¤ì´í‹°ë¸Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œì˜ ê°•ë ¥í•œ ì‚¬ìš©. ë¶ˆí•„ìš”í•œ ì»¤ìŠ¤í…€ ì½”ë“œ ìµœì†Œí™”.

### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ë¶„ì„

#### 4.1 Pandas ì‚¬ìš© âœ…

**Ingestion Pipeline**:
- âœ… 33ì¤„ (ingestion/nodes.py): `data.drop_duplicates()` - ë„¤ì´í‹°ë¸Œ pandas
- âœ… 44ì¤„ (preprocess/nodes.py): `data.dropna(subset=...)` - ë„¤ì´í‹°ë¸Œ pandas
- âœ… 156ì¤„ (preprocess/nodes.py): `data.drop(columns=...)` - ë„¤ì´í‹°ë¸Œ pandas
- âœ… 189ì¤„ (preprocess/nodes.py): `pd.to_datetime(..., errors='coerce')` - ë„¤ì´í‹°ë¸Œ pandas

**Feature Pipeline**:
- âœ… 37ì¤„ (feature/nodes.py): `pd.to_datetime(..., format="%Y%m%d", errors="coerce")` - ë„¤ì´í‹°ë¸Œ pandas
- âœ… 40ì¤„: `s.dt.year.dropna().astype(int).unique()` - Pandas datetime accessor
- âœ… 44ì¤„: `s.dt.dayofweek.isin([5, 6])` - Pandas datetime operations
- âœ… 142ì¤„ (feature/nodes.py): `dropna(subset=[label]).drop_duplicates().reset_index(drop=True)` - ë©”ì†Œë“œ ì²´ì´ë‹

**Preprocess Pipeline**:
- âœ… 108ì¤„ (preprocess/nodes.py): `s_before.replace(mapping)` - ìµœì í™”ëœ pandas replace
- âœ… 111ì¤„: `(s_after != s_before).values.sum()` - ë²¡í„°í™”ëœ ë¹„êµ

**í‰ê°€**: pandas ë„¤ì´í‹°ë¸Œ ë©”ì†Œë“œì˜ ìš°ìˆ˜í•œ ì‚¬ìš©. ë¶ˆí•„ìš”í•œ ì»¤ìŠ¤í…€ ë£¨í”„ë‚˜ apply í•¨ìˆ˜ ì—†ìŒ.

#### 4.2 HuggingFace Datasets ì‚¬ìš© âœ…

**Split Pipeline**:
- âœ… 110ì¤„ (split/nodes.py): `Dataset.from_pandas(cleaned, preserve_index=False)` - ë„¤ì´í‹°ë¸Œ ìƒì„±ì
- âœ… 152ì¤„: `dataset.train_test_split(test_size=..., stratify_by_column=..., seed=...)` - ë„¤ì´í‹°ë¸Œ ë¶„í•  ë©”ì†Œë“œ
- âœ… 165ì¤„: `remain.train_test_split(test_size=..., stratify_by_column=...)` - ì¤‘ì²© ë¶„í• 
- âœ… 208ì¤„: `splits.map(encode, batched=True, num_proc=num_proc)` - ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•œ ë°°ì¹˜ map
- âœ… 212ì¤„: `encoded.cast_column("labels", class_label)` - ë„¤ì´í‹°ë¸Œ ìŠ¤í‚¤ë§ˆ ìºìŠ¤íŒ…
- âœ… 277ì¤„ (split/nodes.py): `split_datasets.map(..., batched=True, num_proc=4, remove_columns=...)` - ê³ ê¸‰ map ì‚¬ìš©

**Train Pipeline**:
- âœ… 246ì¤„ (train/nodes.py): `serialized_datasets.map(tokenize_function, batched=True, num_proc=num_proc, remove_columns=["text"])` - íš¨ìœ¨ì ì¸ í† í°í™”

**í‰ê°€**: HuggingFace Dataset APIì˜ ì™„ë²½í•œ ì‚¬ìš©. ì ì ˆí•œ ì‚¬ìš©:
- ë°°ì¹˜ ì²˜ë¦¬
- ë©€í‹°í”„ë¡œì„¸ì‹± (`num_proc`)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•œ ì»¬ëŸ¼ ì œê±°
- ClassLabelì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ìºìŠ¤íŒ…

#### 4.3 Transformers/Tokenizer ì‚¬ìš© âœ…

**Train Pipeline**:
- âœ… 225ì¤„: `AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)` - ë„¤ì´í‹°ë¸Œ ë¡œë”©
- âœ… 238-243ì¤„: í‘œì¤€ ì¸ìë¥¼ ì‚¬ìš©í•œ Tokenizer í˜¸ì¶œ (truncation, max_length, padding)
- âœ… 374ì¤„ (train/nodes.py): `AutoModelForSequenceClassification.from_pretrained(...)` - ë„¤ì´í‹°ë¸Œ ëª¨ë¸ ë¡œë”©
- âœ… 388ì¤„: `model.gradient_checkpointing_enable()` - ë„¤ì´í‹°ë¸Œ ë©”ì†Œë“œ
- âœ… 446ì¤„ (train/nodes.py): `get_peft_model(model, lora_config)` - PEFT ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ
- âœ… 594ì¤„ (train/nodes.py): `DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8)` - ë„¤ì´í‹°ë¸Œ collator
- âœ… 605ì¤„: `Trainer(...)` - ë„¤ì´í‹°ë¸Œ trainer ì´ˆê¸°í™”

**í‰ê°€**: transformers ì—ì½”ì‹œìŠ¤í…œì˜ ìš°ìˆ˜í•œ ì‚¬ìš©. ì ì ˆí•œ ì‚¬ìš©:
- dtypeê³¼ device_mapì„ ì‚¬ìš©í•œ ëª¨ë¸ ë¡œë”©
- LoRAë¥¼ ìœ„í•œ PEFT
- ë™ì  íŒ¨ë”©ì„ ìœ„í•œ Data collators
- ì½œë°±ì„ ì‚¬ìš©í•œ Trainer API

#### 4.4 ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ âœ…

**Holidays ë¼ì´ë¸ŒëŸ¬ë¦¬** (feature/nodes.py):
- âœ… 41ì¤„: `holidays.KR(years=years)` - ë„¤ì´í‹°ë¸Œ í•œêµ­ íœ´ì¼ ë‹¬ë ¥

**Evaluate ë¼ì´ë¸ŒëŸ¬ë¦¬** (train/nodes.py):
- âœ… 87-90ì¤„: `load_metric("accuracy")` ë“± - ë„¤ì´í‹°ë¸Œ ë©”íŠ¸ë¦­ ë¡œë”©

**NumPy** (train/nodes.py):
- âœ… 84ì¤„: `np.argmax(predictions, axis=1)` - ë²¡í„°í™”ëœ ì—°ì‚°
- âœ… 263ì¤„: `np.mean(token_lengths)`, `np.max()` - ë„¤ì´í‹°ë¸Œ ì§‘ê³„
- âœ… 288ì¤„: `np.percentile(all_lengths, p)` - ë„¤ì´í‹°ë¸Œ ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°

### ì»¤ìŠ¤í…€ ì½”ë“œ ë¶„ì„

#### 4.4.1 í•„ìš”í•œ ì»¤ìŠ¤í…€ ì½”ë“œ âœ…

**ë¼ë²¨ ìŠ¬ë¡¯ ê´€ë¦¬** (split/nodes.py, 18-47ì¤„):
- `_initialize_label_slots`: ë”ë¯¸ ë¼ë²¨ ìŠ¬ë¡¯ ìƒì„±
- `_upsert_labels_into_slots`: ì‹¤ì œ ë¼ë²¨ë¡œ ìŠ¬ë¡¯ ì±„ìš°ê¸°
- **ì •ë‹¹í™”**: ê³ ì •ëœ ë¼ë²¨ ê³µê°„ ìœ ì§€ë¥¼ ìœ„í•œ íŠ¹ì • ìš”êµ¬ì‚¬í•­ (max_classes=1000)
- **ìƒíƒœ**: âœ… í•„ìš”í•œ ì»¤ìŠ¤í…€ ë¡œì§

**Speed/Memory ì½œë°±** (train/nodes.py, 111-182ì¤„):
- `SpeedCallback`, `TorchMemoryCallback`
- **ì •ë‹¹í™”**: Trainerì—ì„œ ì œê³µí•˜ì§€ ì•ŠëŠ” ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
- **ìƒíƒœ**: âœ… Trainer APIì˜ ì ì ˆí•œ í™•ì¥

#### 4.4.2 ìµœì í™”ëœ ì»¤ìŠ¤í…€ ì½”ë“œ âœ…

**ì œìë¦¬ ì •ê·œí™”** (preprocess/nodes.py, 106-126ì¤„):
```python
s_before = df[col].astype(str)
s_after = s_before.replace(mapping)
# ...
df[col] = s_after  # ì œìë¦¬ ì—…ë°ì´íŠ¸
```
- **ì •ë‹¹í™”**: ëŒ€ìš©ëŸ‰ DataFrameì„ ìœ„í•œ ì„±ëŠ¥ ìµœì í™”
- **ìƒíƒœ**: âœ… 340ë§Œ í–‰ì— ëŒ€í•´ ì •ë‹¹í™”ë¨

### ì ì¬ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëŒ€ì²´

#### 4.5.1 Extract Ratio ìƒ˜í”Œë§ (ê²½ë¯¸í•¨)

**í˜„ì¬ êµ¬í˜„** (split/nodes.py, 91-102ì¤„):
```python
if extract_ratio and 0 < extract_ratio < 1:
    if stratify_extract:
        base_table = base_table.groupby(label_column, group_keys=False).apply(
            lambda x: x.sample(frac=extract_ratio, random_state=extract_seed)
        ).reset_index(drop=True)
    else:
        sample_size = int(original_size * extract_ratio)
        base_table = base_table.sample(n=sample_size, random_state=extract_seed)
```

**ëŒ€ì•ˆ** (scikit-learn ì‚¬ìš©):
```python
from sklearn.model_selection import train_test_split

if extract_ratio and 0 < extract_ratio < 1:
    _, base_table = train_test_split(
        base_table,
        test_size=extract_ratio,
        stratify=base_table[label_column] if stratify_extract else None,
        random_state=extract_seed
    )
```

**í‰ê°€**: í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì´ ì¢‹ìŒ. Pandas `sample()`ì´ í‘œì¤€ì´ê³  ëª…í™•í•¨.

### ìœ„ë°˜ ì‚¬í•­

âŒ **ì—†ìŒ** - ëª¨ë“  ì»¤ìŠ¤í…€ ì½”ë“œê°€ ì •ë‹¹í™”ë¨

### ê¶Œì¥ì‚¬í•­

#### 4.1 í•µì‹¬ ê¸°ëŠ¥ì— ëŒ€í•œ ë³€ê²½ ë¶ˆí•„ìš”

í˜„ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì€ ìš°ìˆ˜í•¨. ëª¨ë“  ì»¤ìŠ¤í…€ ì½”ë“œëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì»¤ë²„í•˜ì§€ ì•ŠëŠ” íŠ¹ì • ëª©ì ì— ê¸°ì—¬í•¨.

#### 4.2 ì„ íƒì‚¬í•­: extract_ratioë¥¼ ìœ„í•œ datasets.Dataset ê³ ë ¤

**í˜„ì¬**: `create_dataset`ì—ì„œ Pandas ìƒ˜í”Œë§ (91-102ì¤„)

**ëŒ€ì•ˆ**: HuggingFace Datasetì˜ `select` ë©”ì†Œë“œ ì‚¬ìš©
```python
# ë¨¼ì € Datasetìœ¼ë¡œ ë³€í™˜, ê·¸ ë‹¤ìŒ ìƒ˜í”Œë§
dataset = Dataset.from_pandas(base_table, preserve_index=False)
if extract_ratio and 0 < extract_ratio < 1:
    sample_size = int(len(dataset) * extract_ratio)
    indices = range(sample_size)
    dataset = dataset.select(indices)  # ë˜ëŠ” shuffle().select() ì‚¬ìš©
```

**íŠ¸ë ˆì´ë“œì˜¤í”„**: í˜„ì¬ pandas ì ‘ê·¼ ë°©ì‹ì´ ì´ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ë” ëª…í™•í•¨. ë³€ê²½ ë¶ˆí•„ìš”.

---

## 5. ì¤‘ë³µ ë° ì»¤ìŠ¤í…€ í•¨ìˆ˜ (Duplication and Custom Functions)

**ì ìˆ˜**: 4.5/5

### ì „ì²´ í‰ê°€

âœ… **ìš°ìˆ˜**: ìµœì†Œí•œì˜ ì¤‘ë³µ, ì˜ ë¶„í•´ëœ í—¬í¼ í•¨ìˆ˜, í•„ìš”í•œ ì»¤ìŠ¤í…€ ì½”ë“œë§Œ ì¡´ì¬.

### ì¤‘ë³µ ë¶„ì„

#### 5.1 ì½”ë“œ ì¤‘ë³µ

**5ê°œ íŒŒì´í”„ë¼ì¸ ì „ì²´ì—ì„œ ìœ ì˜ë¯¸í•œ ì¤‘ë³µì´ ë°œê²¬ë˜ì§€ ì•ŠìŒ**.

**ìœ ì‚¬í•œ íŒ¨í„´ (ì¤‘ë³µ ì•„ë‹˜)**:
1. ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸ (preprocess/nodes.py, feature/nodes.py)
   - 41-42ì¤„ (preprocess): `if col in df.columns`
   - 118-123ì¤„ (feature): `if feature in data.columns`
   - **ìƒíƒœ**: âœ… ë‹¤ë¥¸ ë§¥ë½, ì¶”ìƒí™”ëŠ” ê³¼ì‰ ì—”ì§€ë‹ˆì–´ë§ì¼ ê²ƒ

2. ë°ì´í„° ëª¨ì–‘ ë¡œê¹… (ëª¨ë“  íŒŒì´í”„ë¼ì¸)
   - Ingestion: `logger.info(f"Data shape: {raw_data.shape}")`
   - Preprocess: `logger.info(f"Data cleaning complete: {initial_rows} -> {len(data)} rows")`
   - **ìƒíƒœ**: âœ… í‘œì¤€ ë¡œê¹… ê´€í–‰, ì¤‘ë³µ ì•„ë‹˜

#### 5.2 ë°˜ë³µë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ (ê²½ë¯¸í•¨)

**ì´ìŠˆ**: Tokenizer ë¡œë”©ì´ ì—¬ëŸ¬ í•¨ìˆ˜ì— ë‚˜íƒ€ë‚¨

**ìœ„ì¹˜ 1**: `tokenize_datasets` (train/nodes.py, 225-228ì¤„)
```python
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True
)
```

**ìœ„ì¹˜ 2**: `prepare_for_trainer` (train/nodes.py, 342-343ì¤„) - íŒŒì´í”„ë¼ì¸ì— ì—†ìŒ
```python
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True
)
```

**í‰ê°€**:
- â˜‘ï¸ `prepare_for_trainer`ê°€ íŒŒì´í”„ë¼ì¸ì— ì—°ê²°ë˜ì§€ ì•Šì•„ ê²½ë¯¸í•œ ì´ìŠˆ
- ì´ ë…¸ë“œê°€ í™œì„±í™”ë˜ë©´, tokenizerëŠ” ì¹´íƒˆë¡œê·¸ë¥¼ í†µí•´ ì „ë‹¬ë˜ì–´ì•¼ í•¨ (ì„¹ì…˜ 1 ê¶Œì¥ì‚¬í•­ ì°¸ì¡°)

#### 5.3 ì»¤ìŠ¤í…€ í•¨ìˆ˜ ë¶„ì„

##### 5.3.1 í—¬í¼ í•¨ìˆ˜ (ëª¨ë‘ ì •ë‹¹í™”ë¨)

**Split Pipeline í—¬í¼** (split/nodes.py):

| í•¨ìˆ˜ | ë¼ì¸ | ëª©ì  | ì •ë‹¹í™”? |
|----------|-------|---------|--------------|
| `_initialize_label_slots` | 4 | ë”ë¯¸ ë¼ë²¨ ë°°ì—´ ìƒì„± | âœ… ì˜ˆ (ë°‘ì¤„ì€ private í‘œì‹œ) |
| `_upsert_labels_into_slots` | 16 | ì‹¤ì œ ë¼ë²¨ë¡œ ìŠ¬ë¡¯ ì±„ìš°ê¸° | âœ… ì˜ˆ (ë³µì¡í•œ ë¡œì§, ì¬ì‚¬ìš© ê°€ëŠ¥) |
| `make_label2id` | 2 | ë¼ë²¨â†’ID ë§¤í•‘ | âœ… ì˜ˆ (ëª…í™•ì„±, lambdaì¼ ìˆ˜ ìˆì§€ë§Œ ì´ê²ƒì´ ë” ëª…í™•) |
| `make_id2label` | 2 | IDâ†’ë¼ë²¨ ë§¤í•‘ | âœ… ì˜ˆ (ìœ„ì™€ ëŒ€ì¹­) |

**Train Pipeline í—¬í¼** (train/nodes.py):

| í•¨ìˆ˜ | ë¼ì¸ | ëª©ì  | ì •ë‹¹í™”? |
|----------|-------|---------|--------------|
| `is_rank0` | 3 | ë¶„ì‚° í•™ìŠµ ë­í¬ í™•ì¸ | âœ… ì˜ˆ (ë°˜ë³µë˜ëŠ” í™•ì¸, ì¢‹ì€ ì¶”ìƒí™”) |
| `compute_metrics` | 25 | í‰ê°€ ë©”íŠ¸ë¦­ | âœ… ì˜ˆ (Trainer ì½œë°± ìš”êµ¬ì‚¬í•­) |

**í‰ê°€**: ëª¨ë“  í—¬í¼ í•¨ìˆ˜ê°€ ì˜ ì •ë‹¹í™”ë¨. private í•¨ìˆ˜(ë°‘ì¤„ ì ‘ë‘ì‚¬)ì˜ ì ì ˆí•œ ì‚¬ìš©.

##### 5.3.2 ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ (ëª¨ë‘ ì •ë‹¹í™”ë¨)

**Train Pipeline ì½œë°±** (train/nodes.py):

| í´ë˜ìŠ¤ | ë¼ì¸ | ëª©ì  | ì •ë‹¹í™”? |
|-------|-------|---------|--------------|
| `SpeedCallback` | 29 | í•™ìŠµ ì†ë„ ì¶”ì  | âœ… ì˜ˆ (Trainer í™•ì¥) |
| `TorchMemoryCallback` | 32 | GPU ë©”ëª¨ë¦¬ ì¶”ì  | âœ… ì˜ˆ (Trainer í™•ì¥) |

**í‰ê°€**: HuggingFace Trainer ì½œë°± ì‹œìŠ¤í…œì˜ ì ì ˆí•œ í™•ì¥. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œë¡œ ëŒ€ì²´ ë¶ˆê°€ëŠ¥.

##### 5.3.3 ë…¸ë“œ í•¨ìˆ˜ (ëª¨ë‘ í•„ìš”í•¨)

ëª¨ë“  ë…¸ë“œ í•¨ìˆ˜ëŠ” íŠ¹ì • íŒŒì´í”„ë¼ì¸ ëª©ì ì— ê¸°ì—¬í•˜ë©° ì¤‘ë³µë˜ì§€ ì•ŠìŒ. ê°ê° ëª…í™•í•œ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§ (ì„¹ì…˜ 3 ì°¸ì¡°).

### ë¶ˆí•„ìš”í•œ ì»¤ìŠ¤í…€ í•¨ìˆ˜

#### 5.4.1 ì ì¬ì ì¸ ë‹¨ìˆœí™”

**ì¼€ì´ìŠ¤ 1**: `make_label2id`ì™€ `make_id2label` (split/nodes.py, 50-57ì¤„)

**í˜„ì¬**:
```python
def make_label2id(names: List[str]) -> Dict[str, int]:
    """Create label â†’ id mapping preserving index positions."""
    return {name: idx for idx, name in enumerate(names)}

def make_id2label(names: List[str]) -> Dict[int, str]:
    """Create id â†’ label mapping preserving index positions."""
    return {idx: name for idx, name in enumerate(names)}
```

**ì¸ë¼ì¸ dict comprehensionìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥**:
```python
# labelize_and_cast í•¨ìˆ˜ì—ì„œ (200ì¤„)
label2id = {name: idx for idx, name in enumerate(names)}
id2label = {idx: name for idx, name in enumerate(names)}
```

**í‰ê°€**:
- â˜‘ï¸ í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì´ ë” ë‚˜ì€ ì´ìœ :
  1. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„± (í•¨ìˆ˜ë¥¼ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)
  2. ëª…í™•ì„± (ëª…ì‹œì  í•¨ìˆ˜ëª…ì´ ì˜ë„ ë¬¸ì„œí™”)
  3. ì¬ì‚¬ìš©ì„± (ì—¬ëŸ¬ ê³³ì—ì„œ ì‚¬ìš©ë¨)
- **ê¶Œì¥ì‚¬í•­**: í˜„ì¬ ìƒíƒœ ìœ ì§€

**ì¼€ì´ìŠ¤ 2**: `is_rank0()` (train/nodes.py, 52-60ì¤„)

**í˜„ì¬**:
```python
def is_rank0() -> bool:
    """Check if current process is rank 0 in distributed training."""
    rank = int(os.environ.get("RANK", os.environ.get("LOCAL_RANK", 0)))
    return rank == 0
```

**transformers ìœ í‹¸ë¦¬í‹°ë¡œ ëŒ€ì²´ ê°€ëŠ¥**:
```python
from transformers.trainer_utils import get_last_checkpoint, is_main_process
# is_main_process() ëŒ€ì‹  ì‚¬ìš©
```

**í‰ê°€**:
- â˜‘ï¸ í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì´ ë” ê°„ë‹¨í•˜ê³  ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ
- `is_main_process()`ëŠ” `accelerate` ì»¨í…ìŠ¤íŠ¸ í•„ìš”
- **ê¶Œì¥ì‚¬í•­**: í˜„ì¬ ìƒíƒœ ìœ ì§€

### í†µí•© ê¸°íšŒ

#### 5.5 í…ìŠ¤íŠ¸ ì§ë ¬í™” í…œí”Œë¦¿ (ì„ íƒì  ê°œì„ )

**í˜„ì¬** (split/nodes.py, 265-274ì¤„):
```python
def serialize_function(examples):
    texts = []
    for i in range(len(examples[text_columns[0]])):
        if include_column_names:
            parts = [f"{col}: {examples[col][i]}" for col in text_columns]
        else:
            parts = [str(examples[col][i]) for col in text_columns]
        texts.append(separator.join(parts))
    return {"text": texts}
```

**ê°œì„  ì•„ì´ë””ì–´**: í…œí”Œë¦¿ ê¸°ë°˜ ì§ë ¬í™”
```python
# params:train.serializationì—ì„œ
templates:
  default: "{col}: {value}"
  compact: "{value}"
  nlp: "The {col} is {value}"

# ì½”ë“œì—ì„œ
def serialize_function(examples):
    template = templates.get(template_name, "{col}: {value}")
    texts = []
    for i in range(len(examples[text_columns[0]])):
        parts = [template.format(col=col, value=examples[col][i]) for col in text_columns]
        texts.append(separator.join(parts))
    return {"text": texts}
```

**í‰ê°€**:
- í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì´ ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ì¶©ë¶„
- í…œí”Œë¦¿ ì‹œìŠ¤í…œì€ ëª…í™•í•œ ì´ì  ì—†ì´ ë³µì¡ì„± ì¶”ê°€
- **ê¶Œì¥ì‚¬í•­**: ì—¬ëŸ¬ í˜•ì‹ì´ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ í˜„ì¬ ì ‘ê·¼ ë°©ì‹ ìœ ì§€

### ìœ„ë°˜ ì‚¬í•­

âŒ **ì—†ìŒ** - ë¶ˆí•„ìš”í•œ ì¤‘ë³µì´ë‚˜ ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì—†ìŒ

### ê¶Œì¥ì‚¬í•­

#### 5.1 ì¦‰ê°ì ì¸ ë³€ê²½ ë¶ˆí•„ìš”

í˜„ì¬ ì½”ë“œëŠ” ìµœì†Œí•œì˜ ì¤‘ë³µê³¼ ì •ë‹¹í™”ëœ ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¡œ ì˜ êµ¬ì¡°í™”ë˜ì–´ ìˆìŒ.

#### 5.2 í–¥í›„ ê³ ë ¤ì‚¬í•­: í…ìŠ¤íŠ¸ ì§ë ¬í™”ë¥¼ ìœ„í•œ í…œí”Œë¦¿ ì‹œìŠ¤í…œ

í”„ë¡œì íŠ¸ê°€ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì§ë ¬í™” í˜•ì‹ì´ í•„ìš”í•œ ê²½ìš° (ì˜ˆ: ë‹¤ë¥¸ ëª¨ë¸ì´ë‚˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ìœ„í•´) í…œí”Œë¦¿ ì‹œìŠ¤í…œ êµ¬í˜„ì„ ê³ ë ¤. í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì€ ë‹¨ì¼ í˜•ì‹ì— ì í•©í•¨.

#### 5.3 `prepare_for_trainer`ê°€ í™œì„±í™”ë˜ë©´ tokenizer ë¡œë”© ëª¨ë‹ˆí„°ë§

ì—°ê²°ì´ ëŠê¸´ `prepare_for_trainer` ë…¸ë“œê°€ íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€ë˜ë©´, ì¤‘ë³µ ë¡œë”©ì„ í”¼í•˜ê¸° ìœ„í•´ tokenizerê°€ ì¹´íƒˆë¡œê·¸ë¥¼ í†µí•´ ì „ë‹¬ë˜ë„ë¡ ë³´ì¥ (ì„¹ì…˜ 1.5 ê¶Œì¥ì‚¬í•­ ì°¸ì¡°).

---

## ì¢…í•© í‰ê°€ (Overall Evaluation)

### ê¸°ì¤€ë³„ ì ìˆ˜

| í‰ê°€ ê¸°ì¤€ | ì ìˆ˜ | ë“±ê¸‰ |
|-----------|-------|-------|
| 1. Catalog ê¸°ë°˜ I/O | 4.5/5 | ìš°ìˆ˜ |
| 2. MLflow Hook ìë™ ê°œì… | 3.5/5 | ì–‘í˜¸ (ê°œì„ ë¨) |
| 3. ëª¨ë“ˆì„± ë¶„ë¦¬ | 4.8/5 | ìš°ìˆ˜ |
| 4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ í™œìš© | 4.8/5 | ìš°ìˆ˜ |
| 5. ì¤‘ë³µ ë° ì»¤ìŠ¤í…€ í•¨ìˆ˜ | 4.5/5 | ìš°ìˆ˜ |
| **ì „ì²´** | **4.2/5** | **ì–‘í˜¸ - ì†Œí­ ê°œì„  í•„ìš”** |

### ìƒì„¸ ë°œê²¬ ì‚¬í•­

#### ê°•ì 

1. **ì¼ê´€ëœ ì¹´íƒˆë¡œê·¸ ì‚¬ìš©** (4.5/5)
   - ëª¨ë“  íŒŒì´í”„ë¼ì¸ I/Oê°€ catalog.ymlì„ í†µí•´ ì ì ˆíˆ ê´€ë¦¬ë¨
   - ì¤‘ê°„ ë‹¨ê³„ë¥¼ ìœ„í•œ MemoryDatasetì˜ ì ì ˆí•œ ì‚¬ìš©
   - ì ì ˆí•œ ì˜ì†í™” ì „ëµ (ë°ì´í„°ëŠ” ParquetDataset, ë³µì¡í•œ ê°ì²´ëŠ” PickleDataset)

2. **ê°•ë ¥í•œ ëª¨ë“ˆì„±** (4.8/5)
   - ë…¸ë“œë³„ ëª…í™•í•œ ë‹¨ì¼ ì±…ì„
   - ì ì ˆí•œ ê°€ì‹œì„±(ë°‘ì¤„ ì ‘ë‘ì‚¬)ì„ ê°€ì§„ ì˜ ë¶„í•´ëœ í—¬í¼ í•¨ìˆ˜
   - íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ê°„ ìµœì†Œí•œì˜ ê²°í•©

3. **ìš°ìˆ˜í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©** (4.8/5)
   - ë°ì´í„° ì—°ì‚°ì„ ìœ„í•œ ë„¤ì´í‹°ë¸Œ pandas ë©”ì†Œë“œ
   - íš¨ìœ¨ì ì¸ HuggingFace Dataset API ì‚¬ìš© (batched=True, num_proc, remove_columns)
   - ì½œë°±ì„ ì‚¬ìš©í•œ ì ì ˆí•œ transformers Trainer í†µí•©

4. **ìµœì†Œí•œì˜ ì¤‘ë³µ** (4.5/5)
   - ìœ ì˜ë¯¸í•œ ì½”ë“œ ì¤‘ë³µ ì—†ìŒ
   - ëª¨ë“  ì»¤ìŠ¤í…€ ì½”ë“œê°€ íŠ¹ì • ëª©ì ì— ê¸°ì—¬
   - í—¬í¼ í•¨ìˆ˜ê°€ ì ì ˆíˆ ì¶”ìƒí™”ë¨

#### ê°œì„  ì˜ì—­

1. **MLflow í†µí•©** (3.5/5) - **ìš°ì„ ìˆœìœ„** - âœ… **ìˆ˜ì • ì™„ë£Œ**
   - âœ… `tokenize_datasets`ì—ì„œ ì§ì ‘ `mlflow.log_*` í˜¸ì¶œ ì œê±°ë¨ (298ì¤„)
   - âœ… MlflowArtifactDatasetê³¼ Trainerì˜ `report_to=["mlflow"]` ì ì ˆíˆ ì‚¬ìš©
   - **ì¡°ì¹˜**: ìˆ˜ë™ ë¡œê¹… ì œê±°, ë©”íŠ¸ë¦­ì„ ë°ì´í„° ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜ - **ì™„ë£Œ**

2. **Tokenizer ê´€ë¦¬** - âœ… **í˜„í–‰ ìœ ì§€ (ì„¤ê³„ ê²°ì •)**
   - Tokenizerê°€ ë…¸ë“œ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë¡œë“œë¨
   - **ì„¤ê³„ ê·¼ê±°**: ë‹¨ì¼ ë…¸ë“œ ë‚´ë¶€ì—ì„œë§Œ ì‚¬ìš©, ì™¸ë¶€ ì „ë‹¬ ë¶ˆí•„ìš”
   - **ì¡°ì¹˜**: ì—†ìŒ - í˜„ì¬ êµ¬ì¡°ê°€ ì ì ˆí•¨

3. **ì—°ê²° ëŠê¸´ ë…¸ë“œ** (ê²½ë¯¸í•¨)
   - `prepare_for_trainer`ê°€ ì •ì˜ë˜ì—ˆì§€ë§Œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
   - **ì¡°ì¹˜**: ì œê±°í•˜ê±°ë‚˜ í–¥í›„ ì‘ì—…ìœ¼ë¡œ ë¬¸ì„œí™”

### ìš°ì„ ìˆœìœ„ ì¡°ì¹˜ í•­ëª©

#### ê¸´ê¸‰ (ë°˜ë“œì‹œ ìˆ˜ì •) - âœ… ì™„ë£Œ

1. **ì§ì ‘ MLflow ë¡œê¹… ì œê±°** (train/nodes.py, 298ì¤„) - âœ… **ì™„ë£Œ**
   - ë°ì´í„° ì¶œë ¥ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´
   - kedro-mlflow í›…ì´ ë©”íŠ¸ë¦­ ì¶”ì  ì²˜ë¦¬í•˜ë„ë¡ í•¨
   - **ì†Œìš” ì‹œê°„**: 15ë¶„
   - **ì˜í–¥ë°›ëŠ” íŒŒì¼**:
     - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/nodes.py` (298ì¤„)

#### ì¤‘ìš” (ìˆ˜ì •í•´ì•¼ í•¨)

2. **í…ìŠ¤íŠ¸ ì§ë ¬í™” ë²¡í„°í™” ê°œì„ ** - âœ… **ì™„ë£Œ**
   - Python ë£¨í”„ë¥¼ pandas ë²¡í„°í™”ë¡œ ê°œì„ 
   - ì„±ëŠ¥ í–¥ìƒ (íŠ¹íˆ ë§ì€ ì»¬ëŸ¼ ì²˜ë¦¬ ì‹œ 2-3ë°°)
   - **ì†Œìš” ì‹œê°„**: 10ë¶„
   - **ì˜í–¥ë°›ëŠ” íŒŒì¼**:
     - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/split/nodes.py` (serialize_to_text ìµœì í™”)

#### ì„ íƒ ì‚¬í•­ (ì¢‹ìŒ)

3. **`prepare_for_trainer` ë¬¸ì„œí™” ë˜ëŠ” ì œê±°**
   - ë…¸ë“œê°€ ì •ì˜ë˜ì—ˆì§€ë§Œ ì—°ê²°ë˜ì§€ ì•ŠìŒ
   - **ì†Œìš” ì‹œê°„**: 5ë¶„
   - **ì˜í–¥ë°›ëŠ” íŒŒì¼**:
     - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/nodes.py` (TODO ì¶”ê°€ ë˜ëŠ” ì œê±°)

4. **í…ìŠ¤íŠ¸ ì§ë ¬í™”ë¥¼ ìœ„í•œ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ê³ ë ¤**
   - ì—¬ëŸ¬ í˜•ì‹ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ
   - **ì†Œìš” ì‹œê°„**: 2ì‹œê°„
   - **ì˜í–¥ë°›ëŠ” íŒŒì¼**:
     - `/home/user/projects/kedro_project/account-tax/conf/base/parameters/training.yml` (í…œí”Œë¦¿ ì¶”ê°€)
     - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/split/nodes.py` (serialize_to_text ë¦¬íŒ©í„°ë§)

### ì„¤ê³„ ì² í•™ ì¤€ìˆ˜

**ëŒ€ì¹­í™” (Pattern/Symmetry)**: âœ… ìš°ìˆ˜
- ëª¨ë“  íŒŒì´í”„ë¼ì¸ì—ì„œ ì¼ê´€ëœ íŒ¨í„´
- ìœ ì‚¬í•œ ë…¸ë“œ êµ¬ì¡° (ì¹´íƒˆë¡œê·¸ì—ì„œ ì…ë ¥, ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„°, ì¹´íƒˆë¡œê·¸ë¡œ ì¶œë ¥)
- ëŒ€ì¹­ì ì¸ í—¬í¼ í•¨ìˆ˜ (make_label2id / make_id2label)

**ëª¨ë“ˆí™” (Modularity)**: âœ… ìš°ìˆ˜
- ëª…í™•í•œ I/O ê³„ì•½ìœ¼ë¡œ ë…¸ë“œ ê¸°ë°˜ ë¶„ë¦¬
- ë‹¨ê³„ ê°„ ìµœì†Œí•œì˜ ê²°í•©
- í—¬í¼ í•¨ìˆ˜ì™€ ì½œë°±ì˜ ì ì ˆí•œ ì‚¬ìš©

**ìˆœì„œí™” (Ordering)**: âœ… ìš°ìˆ˜
- ëª…í™•í•œ ì¸ê³¼ê´€ê³„: Ingestion â†’ Preprocess â†’ Feature â†’ Split â†’ Train
- ë°ì´í„°ê°€ ì¹´íƒˆë¡œê·¸ ì •ì˜ ë°ì´í„°ì…‹ì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ íë¦„
- Kedroë¥¼ í†µí•œ íŒŒì´í”„ë¼ì¸ ì˜ì¡´ì„± ì ì ˆíˆ ê´€ë¦¬ë¨

### í–¥í›„ ê°œë°œì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­

1. **MLflow Hooks**
   - ê³ ê¸‰ ë©”íŠ¸ë¦­ ì¶”ì ì„ ìœ„í•œ ì»¤ìŠ¤í…€ í›… ìƒì„± ê³ ë ¤
   - í”„ë¡œì íŠ¸ ê°€ì´ë“œë¼ì¸ì— í›… ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ ë¬¸ì„œí™”

2. **í…ŒìŠ¤íŠ¸ ì „ëµ**
   - í—¬í¼ í•¨ìˆ˜(ë¼ë²¨ ìŠ¬ë¡¯, ë§¤í•‘)ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€
   - íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ì— ëŒ€í•œ í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
   - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ MLflow ëª¨í‚¹

3. **ë¬¸ì„œí™”**
   - MLflow í†µí•© íŒ¨í„´ìœ¼ë¡œ architecture.md ì—…ë°ì´íŠ¸
   - íŠ¹ì • ì»¤ìŠ¤í…€ ì½”ë“œê°€ ì¡´ì¬í•˜ëŠ” ì´ìœ  ë¬¸ì„œí™” (ë¼ë²¨ ìŠ¬ë¡¯, ì½œë°±)
   - ê° íŒŒì´í”„ë¼ì¸ ì¶œë ¥ì— ëŒ€í•œ ë°ì´í„° ê³„ì•½ ë¬¸ì„œ ì¶”ê°€

4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
   - íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œê°„ ì¶”ì 
   - ëŒ€ìš©ëŸ‰ ë°ì´í„° ì‘ì—…ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
   - ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¡œê¹… (null ë¹„ìœ¨, ì¤‘ë³µ ë¹„ìœ¨)

### ê²°ë¡ 

ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ **Kedro ë° MLOps ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ê°•ë ¥íˆ ì¤€ìˆ˜**í•©ë‹ˆë‹¤. êµ¬í˜„ì€ ëª…í™•í•œ ê´€ì‹¬ì‚¬ ë¶„ë¦¬, ì ì ˆí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ ì‚¬ìš©, ìµœì†Œí•œì˜ ë¶ˆí•„ìš”í•œ ì½”ë“œë¡œ ì˜ êµ¬ì¡°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê°œì„  í•„ìš” ì‚¬í•­ì´ì—ˆë˜ ì§ì ‘ MLflow ë¡œê¹… ì½”ë“œ ì œê±°ëŠ” **ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤**. ì´ì œ íŒŒì´í”„ë¼ì¸ì€ í”„ë¡œì íŠ¸ì˜ ì„¤ê³„ ì² í•™ê³¼ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.

**ì „ì²´ ê¶Œì¥ì‚¬í•­**: âœ… **ê¸´ê¸‰ ìˆ˜ì • ì™„ë£Œ** - í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ.

---

## ë¶€ë¡: íŒŒì¼ ì°¸ì¡°

### ê²€í† ëœ íŒŒì¼

1. **Ingestion Pipeline**
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/ingestion/nodes.py` (167ì¤„)
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/ingestion/pipeline.py` (42ì¤„)

2. **Preprocess Pipeline**
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/preprocess/nodes.py` (218ì¤„)
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/preprocess/pipeline.py` (54ì¤„)

3. **Feature Pipeline**
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/feature/nodes.py` (148ì¤„)
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/feature/pipeline.py` (30ì¤„)

4. **Split Pipeline**
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/split/nodes.py` (296ì¤„)
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/split/pipeline.py` (58ì¤„)

5. **Train Pipeline**
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/nodes.py` (683ì¤„)
   - `/home/user/projects/kedro_project/account-tax/src/account_tax/pipelines/train/pipeline.py` (24ì¤„)

6. **ì„¤ì • íŒŒì¼**
   - `/home/user/projects/kedro_project/account-tax/conf/base/catalog.yml` (117ì¤„)
   - `/home/user/projects/kedro_project/account-tax/conf/base/parameters/data.yml` (61ì¤„)
   - `/home/user/projects/kedro_project/account-tax/conf/base/parameters/training.yml` (102ì¤„)
   - `/home/user/projects/kedro_project/account-tax/conf/base/mlflow.yml` (14ì¤„)

### ì´ ê²€í† ëœ ì½”ë“œ ë¼ì¸

- **íŒŒì´í”„ë¼ì¸ ì½”ë“œ**: 1,620ì¤„
- **ì„¤ì •**: 294ì¤„
- **ì´**: 1,914ì¤„

### ê²€í†  ë°©ë²•ë¡ 

1. ëª¨ë“  íŒŒì´í”„ë¼ì¸ íŒŒì¼ê³¼ ì„¤ì • ì½ê¸°
2. I/O ì •ì˜ë¥¼ ìœ„í•œ catalog.yml í™•ì¸
3. ì§ì ‘ íŒŒì¼ ì‘ì—…ê³¼ MLflow í˜¸ì¶œ ê²€ìƒ‰
4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ì†Œë“œ ì‚¬ìš© vs ì»¤ìŠ¤í…€ ì½”ë“œ ë¶„ì„
5. ì½”ë“œ ì¤‘ë³µê³¼ ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì •ë‹¹í™” ì‹ë³„
6. architecture.md ë° CLAUDE.md ì›ì¹™ê³¼ êµì°¨ ì°¸ì¡°