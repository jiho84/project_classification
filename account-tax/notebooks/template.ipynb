{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Account-Tax Pipeline Data Exploration Template\n",
    "\n",
    "주피터 노트북에서 `account-tax` 파이프라인의 데이터를 로드하고 탐색하는 템플릿입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Kedro 통합\n",
    "from kedro.framework.startup import bootstrap_project\n",
    "from kedro.framework.session import KedroSession\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# HuggingFace datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 화면 표시 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kedro Catalog을 통한 데이터 로드 (권장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 부트스트랩\n",
    "project_path = Path.cwd().parent  # notebooks/에서 실행 시\n",
    "bootstrap_project(project_path)\n",
    "\n",
    "# Kedro 세션 생성\n",
    "with KedroSession.create(project_path=project_path) as session:\n",
    "    context = session.load_context()\n",
    "    catalog = context.catalog\n",
    "\n",
    "    # 데이터셋 로드\n",
    "    raw_data = catalog.load(\"raw_account_data\")  # Parquet\n",
    "    standardized_data = catalog.load(\"standardized_data\")  # Parquet\n",
    "    validated_data = catalog.load(\"validated_data\")  # Parquet\n",
    "    base_table = catalog.load(\"base_table\")  # Parquet (features 포함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기본 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형태 확인\n",
    "print(f\"Shape: {base_table.shape}\")\n",
    "print(f\"Columns: {base_table.columns.tolist()}\")\n",
    "print(f\"Memory: {base_table.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# 기본 통계\n",
    "base_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 몇 행 확인\n",
    "base_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 확인\n",
    "base_table.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "base_table.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HuggingFace Dataset 로드 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle 파일 로드\n",
    "with open('../data/05_model_input/serialized_datasets.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# 구조 확인\n",
    "print(f\"Type: {type(datasets)}\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 split 정보 확인\n",
    "for split_name, dataset in datasets.items():\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(f\"  Rows: {len(dataset)}\")\n",
    "    print(f\"  Columns: {dataset.column_names}\")\n",
    "    print(f\"  Features: {dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터 확인\n",
    "print(\"Train set sample:\")\n",
    "print(datasets['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 라벨 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame으로 변환 (전체 또는 샘플)\n",
    "train_df = datasets['train'].to_pandas()\n",
    "# train_df = datasets['train'].select(range(10000)).to_pandas()  # 샘플링\n",
    "\n",
    "# 라벨 분포\n",
    "label_counts = train_df['labels'].value_counts()\n",
    "print(f\"\\nLabel distribution (top 10):\")\n",
    "print(label_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 분포 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 상위 20개 라벨\n",
    "label_counts.head(20).plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Top 20 Label Distribution')\n",
    "axes[0].set_xlabel('Label')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# 텍스트 길이 분포\n",
    "text_lengths = train_df['text'].str.len()\n",
    "axes[1].hist(text_lengths, bins=50, edgecolor='black')\n",
    "axes[1].set_title('Text Length Distribution')\n",
    "axes[1].set_xlabel('Character Count')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 무작위 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위 샘플 추출\n",
    "import random\n",
    "random.seed(42)\n",
    "indices = random.sample(range(len(datasets['train'])), k=5)\n",
    "samples = datasets['train'].select(indices)\n",
    "\n",
    "# 샘플 표시\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {i+1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Text: {sample['text']}\")\n",
    "    print(f\"Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Token Length Report 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 리포트 로드\n",
    "with open('../data/08_reporting/token_length_report.json', 'r') as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "# 예쁘게 출력\n",
    "import pprint\n",
    "pprint.pprint(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 통계 확인\n",
    "print(f\"Overall mean token length: {report['overall']['mean']}\")\n",
    "print(f\"Overall max token length: {report['overall']['max']}\")\n",
    "print(f\"\\nTrain split stats:\")\n",
    "print(f\"  Mean: {report['per_split']['train']['mean']}\")\n",
    "print(f\"  Max: {report['per_split']['train']['max']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 커스텀 분석 영역\n",
    "\n",
    "아래에 추가 분석 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 분석 코드 작성\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
