#!/usr/bin/env python3
"""
PEFT + DeepSpeed í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (DeepSpeed ëŸ°ì²˜ìš© ìµœì†Œí™”)
ì‹¤í–‰ ì˜ˆì‹œ: deepspeed --num_gpus=4 train.py --config conf/experiment.yaml
"""

import os, torch, deepspeed
from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding
from peft import LoraConfig, get_peft_model
from omegaconf import OmegaConf
import mlflow
import argparse
from datetime import datetime
import logging
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
import time
import random
import torch.distributed as dist
from pathlib import Path

# HF Datasets
from datasets import DatasetDict, Dataset, load_from_disk
import pickle
import json

# ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ì„í¬íŠ¸
from utils import MetricTracker, GPUMonitor, RankAwareLogger, PathManager

# í™˜ê²½ ì„¤ì •
os.environ["TOKENIZERS_PARALLELISM"] = "false"
local_rank = int(os.getenv("LOCAL_RANK", 0))
torch.cuda.set_device(local_rank)



# ==================== ê¸°ì¡´ ì½”ë“œ ê³„ì† ====================

# í†µí•©ëœ í† í¬ë‚˜ì´ì € ì„¤ì • í•¨ìˆ˜
def setup_tokenizer(model_name: str, trust_remote_code: bool = True):
    """
    í† í¬ë‚˜ì´ì € ìƒì„± ë° Qwen3 ìµœì í™” ì„¤ì • í†µí•© í•¨ìˆ˜
    """
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=trust_remote_code
    )
    
    # íŒ¨ë”© ë°©í–¥ ì„¤ì • (í›ˆë ¨ìš©)
    tokenizer.padding_side = "right"
    
    # í† í° ID í™•ì¸ ë° ê²€ì¦
    if local_rank == 0:
        print(f"ğŸ” í† í¬ë‚˜ì´ì € í† í° ì •ë³´:")
        print(f"   - PAD token: '{tokenizer.pad_token}' (ID: {tokenizer.pad_token_id})")
        print(f"   - EOS token: '{tokenizer.eos_token}' (ID: {tokenizer.eos_token_id})")
        print(f"   - Vocab size: {tokenizer.vocab_size}")
        
        # Qwen3ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ PADì™€ EOSê°€ êµ¬ë¶„ë˜ì–´ ìˆìŒ
        if tokenizer.pad_token_id == tokenizer.eos_token_id:
            print("âš ï¸ ê²½ê³ : PADì™€ EOS í† í°ì´ ë™ì¼í•©ë‹ˆë‹¤. ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± ìˆìŒ.")
        else:
            print("âœ… PADì™€ EOS í† í°ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    return tokenizer

# í™˜ê²½ ìë™ ì„¤ì • í•¨ìˆ˜ (ìµœì†Œí™”)
def auto_setup_environment():
    """DeepSpeed ëŸ°ì²˜ í™˜ê²½ ìë™ ì„¤ì •"""
    # Intel oneMKL ì˜¤ë¥˜ ë°©ì§€ í™˜ê²½ë³€ìˆ˜
    os.environ["MKL_SERVICE_FORCE_INTEL"] = "1"  #oneMKL ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¥¼ ê°•ì œë¡œ Intel êµ¬í˜„ìœ¼ë¡œ ê³ ì •. AMD/ARM í™˜ê²½ì—ì„œ ë¶ˆì•ˆì •í•œ â€˜ILP64 vs LP64â€™ ì¶©ëŒì„ ì˜ˆë°©.
    os.environ["MKL_THREADING_LAYER"] = "GNU"  #oneMKL ìŠ¤ë ˆë”© ë ˆì´ì–´ë¥¼ GNUë¡œ ì„¤ì •. ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ ì„¤ì •.
    os.environ["OMP_NUM_THREADS"] = "1"  #OpenMP ìŠ¤ë ˆë”© ë ˆì´ì–´ë¥¼ 1ë¡œ ì„¤ì •. ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ ì„¤ì •.
    os.environ["MKL_NUM_THREADS"] = "1"  #oneMKL ìŠ¤ë ˆë”© ë ˆì´ì–´ë¥¼ 1ë¡œ ì„¤ì •. ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ ì„¤ì •.
    
    # CUDA ê´€ë ¨ ì„¤ì •
    os.environ["CUDA_LAUNCH_BLOCKING"] = "1"  #CUDA ëŸ°íƒ€ì„ ë¸”ë¡œí‚¹ ëª¨ë“œ í™œì„±í™”. ë””ë²„ê¹… ë° ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì¶”ì ì— ë„ì›€.
    torch.backends.cuda.matmul.allow_tf32 = True  #CUDA ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆì—ì„œ TF32 í™œì„±í™”. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì„¤ì •.
    torch.backends.cudnn.allow_tf32 = True  #CUDNNì—ì„œ TF32 í™œì„±í™”. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì„¤ì •.
    if hasattr(torch.backends.cuda, 'enable_flash_sdp'):
        torch.backends.cuda.enable_flash_sdp(True)  #Flash Attention 2 í™œì„±í™”. ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì„¤ì •.
    if local_rank == 0:
        world_size = int(os.environ.get('WORLD_SIZE', '1'))
        print(f"ğŸš€ DeepSpeed ëŸ°ì²˜ í™˜ê²½:")
        print(f"   World Size: {world_size}")
        print(f"   Local Rank: {local_rank}")
        print(f"   ğŸ”§ Intel oneMKL ì•ˆì •í™” í™˜ê²½ë³€ìˆ˜ ì„¤ì •ë¨")
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.device_count()}ê°œ")

# ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ë‚´ì¥ í•¨ìˆ˜ í™œìš©)
def pkl_to_arrow_once(pkl_path, arrow_dir, shard_size="500MB"):
    """PKL â†’ Arrow(ìë™ ìƒ¤ë”©) í•œ ë²ˆë§Œ ë³€í™˜ with checksum-based caching"""
    import hashlib
    
    # ì²´í¬ì„¬ ê³„ì‚° í•¨ìˆ˜
    def calculate_file_checksum(filepath, chunk_size=8192):
        """íŒŒì¼ì˜ MD5 ì²´í¬ì„¬ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(chunk_size), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    # ë©”íƒ€ë°ì´í„° ê²½ë¡œ
    meta_path = os.path.join(arrow_dir, "meta.json")
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ê²½ë¡œ (pkl íŒŒì¼ì˜ metadata í‚¤ ì „ì²´ ì €ì¥)
    full_metadata_path = os.path.join(arrow_dir, "dataset_full_metadata.json")
    
    # ê¸°ì¡´ ìºì‹œ í™•ì¸
    if os.path.exists(arrow_dir) and os.path.exists(meta_path):
        try:
            with open(meta_path, "r") as f:
                meta = json.load(f)
            
            # ì²´í¬ì„¬ ë° ê²½ë¡œ ê²€ì¦
            if "pkl_checksum" in meta and "pkl_path" in meta:
                current_checksum = calculate_file_checksum(pkl_path)
                if (meta["pkl_checksum"] == current_checksum and 
                    meta["pkl_path"] == pkl_path):
                    if local_rank == 0:
                        print(f"âœ… Arrow ìºì‹œ ìœ íš¨ (ì²´í¬ì„¬ ì¼ì¹˜): {arrow_dir}")
                    return  # ìºì‹œ ìœ íš¨, ë³€í™˜ ìŠ¤í‚µ
                else:
                    if local_rank == 0:
                        print(f"ğŸ”„ Arrow ìºì‹œ ë¬´íš¨í™” (ì²´í¬ì„¬/ê²½ë¡œ ë³€ê²½)")
                        print(f"   ì´ì „ ê²½ë¡œ: {meta.get('pkl_path', 'N/A')}")
                        print(f"   í˜„ì¬ ê²½ë¡œ: {pkl_path}")
        except Exception as e:
            if local_rank == 0:
                print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ìºì‹œ ì¬ìƒì„±
    os.makedirs(arrow_dir, exist_ok=True)
    
    if local_rank == 0:
        print(f"ğŸ“¦ PKL â†’ Arrow ë³€í™˜ ì‹œì‘: {pkl_path}")
        print(f"   ëŒ€ìƒ: {arrow_dir}")
    
    with open(pkl_path, "rb") as f:
        data = pickle.load(f)

    # Handle both old structure (nested under data['data']) and new structure (flat)
    # Check if this is the old structure with nested 'data'
    if 'data' in data and isinstance(data['data'], dict) and 'train' in data['data']:
        # Old structure: data is nested under data['data']
        actual_data = data['data']
    else:
        # New structure: train/val/test are at top level
        actual_data = data
    
    # Create datasets with proper split names
    dsets = DatasetDict({
        "train": Dataset.from_dict(actual_data["train"]),
        "validation": Dataset.from_dict(actual_data.get("validation", actual_data.get("val", {}))),
        "test": Dataset.from_dict(actual_data["test"])
    })
    dsets.save_to_disk(arrow_dir, max_shard_size=shard_size)  # ìë™ ë¶„í• 
    
    # Extract num_classes from the correct location
    num_classes = None
    if 'metadata' in data:
        # Try direct access first
        if 'num_classes' in data['metadata']:
            num_classes = data['metadata']['num_classes']
        # If not found, check inside label_mapping
        elif 'label_mapping' in data['metadata'] and 'num_classes' in data['metadata']['label_mapping']:
            num_classes = data['metadata']['label_mapping']['num_classes']
    
    # If still not found, count unique labels
    if num_classes is None:
        all_labels = set()
        for split in ['train', 'val', 'validation', 'test']:
            if split in actual_data and 'labels' in actual_data[split]:
                all_labels.update(actual_data[split]['labels'])
        num_classes = len(all_labels)
        if local_rank == 0:
            print(f"âš ï¸ num_classes not found in metadata, calculated from labels: {num_classes}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥ (ì²´í¬ì„¬ ë° ê²½ë¡œ í¬í•¨)
    pkl_checksum = calculate_file_checksum(pkl_path)
    with open(meta_path, "w") as f:
        json.dump({
            "num_classes": num_classes,
            "created_at": datetime.now().isoformat(),
            "pkl_path": pkl_path,
            "pkl_checksum": pkl_checksum,
            "pkl_size": os.path.getsize(pkl_path)
        }, f)
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ì €ì¥ (pklì˜ metadata í‚¤ ì „ì²´)
    # Ensure num_classes is at the top level of metadata
    full_metadata = data.get("metadata", {}).copy()
    if 'num_classes' not in full_metadata:
        full_metadata['num_classes'] = num_classes
    
    with open(full_metadata_path, "w") as f:
        json.dump(full_metadata, f, indent=2, ensure_ascii=False, default=str)
    
    if local_rank == 0:
        print(f"âœ… Arrow ë³€í™˜ ì™„ë£Œ (ì²´í¬ì„¬: {pkl_checksum[:8]}...)")
        print(f"âœ… ì „ì²´ ë©”íƒ€ë°ì´í„° ì €ì¥: {full_metadata_path}")

def build_loaders(cfg):
    """HF Datasets APIë¡œ DataLoader ë¹Œë“œ - PKL íŒŒì¼ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì‚¬ìš©"""
    arrow_dir = os.path.join(cfg.cache_dir, "hf_arrow")
    
    # rank 0ì—ì„œë§Œ PKL â†’ Arrow ë³€í™˜ ìˆ˜í–‰
    if local_rank == 0:
        pkl_to_arrow_once(cfg.data.dataset_all_path, arrow_dir)   # â‘ 
    
    # ë‹¤ë¥¸ rankëŠ” ë³€í™˜ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (ê°„ë‹¨í•œ ë™ê¸°í™”)
    if torch.distributed.is_initialized():
        torch.distributed.barrier()

    dsdict = load_from_disk(arrow_dir, keep_in_memory=False)  # â‘¡ mmap ë¡œë“œ with memory optimization
    train_ds = dsdict["train"]
    val_ds = dsdict["validation"]
    test_ds = dsdict["test"]

    # ğŸš« ê°•ì œ ë¶„í•  ë¡œì§ ì œê±° - PKL íŒŒì¼ì˜ ë°ì´í„° êµ¬ì¡° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if local_rank == 0:
        print(f"ğŸ“Š PKL íŒŒì¼ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì‚¬ìš©:")
        print(f"   Train: {len(train_ds):,}ê°œ ìƒ˜í”Œ")
        print(f"   Validation: {len(val_ds):,}ê°œ ìƒ˜í”Œ")
        print(f"   Test: {len(test_ds):,}ê°œ ìƒ˜í”Œ")

    # â‘¢ (ì„ íƒ) ì„œë¸Œì…‹ ì¶”ì¶œ
    if cfg.data.extract_ratio < 1.0:
        n_train = int(len(train_ds) * cfg.data.extract_ratio)
        n_val = int(len(val_ds) * cfg.data.extract_ratio)
        n_test = int(len(test_ds) * cfg.data.extract_ratio)
        
        train_ds = train_ds.shuffle(seed=42).select(range(n_train))
        val_ds = val_ds.shuffle(seed=42).select(range(n_val))
        test_ds = test_ds.shuffle(seed=42).select(range(n_test))
        
        if local_rank == 0:
            print(f"ğŸ“ ë°ì´í„° ì¶”ì¶œ ë¹„ìœ¨ {cfg.data.extract_ratio}:")
            print(f"   Train: {len(train_ds):,}ê°œ")
            print(f"   Validation: {len(val_ds):,}ê°œ")
            print(f"   Test: {len(test_ds):,}ê°œ")

    # â‘£ í† í¬ë‚˜ì´ì¦ˆ batched map - í†µí•©ëœ í† í¬ë‚˜ì´ì € ì„¤ì • ì‚¬ìš©
    tok = setup_tokenizer(cfg.model.name, trust_remote_code=True)
    
    def tok_fn(batch):
        return tok(
            batch["text"], 
            truncation=True, 
            max_length=cfg.data.max_length,
            add_special_tokens=True,  # ëª…ì‹œì ìœ¼ë¡œ EOS í† í° ì¶”ê°€
            padding=False  # DataCollatorê°€ ë°°ì¹˜ ìƒì„± ì‹œ íŒ¨ë”© ì²˜ë¦¬
        )

    # í† í¬ë‚˜ì´ì§• í›„ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸° (input_ids, attention_mask, labels)
    cols_to_remove = ["text", "original_labels"]  # ë¬¸ì œê°€ ë˜ëŠ” ì»¬ëŸ¼ë“¤ ì œê±°
    train_ds = train_ds.map(tok_fn, batched=True, remove_columns=cols_to_remove, num_proc=os.cpu_count())
    val_ds = val_ds.map(tok_fn, batched=True, remove_columns=cols_to_remove, num_proc=os.cpu_count())
    test_ds = test_ds.map(tok_fn, batched=True, remove_columns=cols_to_remove, num_proc=os.cpu_count())

    # â‘¤ í…ì„œ í¬ë§· ì§€ì • â†’ ì»¤ìŠ¤í…€ Dataset í•„ìš” ì—†ìŒ
    train_ds.set_format("torch")
    val_ds.set_format("torch")
    test_ds.set_format("torch")

    collate = DataCollatorWithPadding(tok)

    # DistributedSampler ì ìš©
    from torch.utils.data import DataLoader, DistributedSampler
    train_sampler = DistributedSampler(train_ds, shuffle=True)
    val_sampler = DistributedSampler(val_ds, shuffle=False)
    test_sampler = DistributedSampler(test_ds, shuffle=False)

    train_loader = DataLoader(train_ds, batch_size=cfg.deepspeed.train_micro_batch_size_per_gpu,
                              sampler=train_sampler, collate_fn=collate,
                              num_workers=cfg.hardware.num_workers, pin_memory=cfg.hardware.pin_memory,
                              prefetch_factor=2, persistent_workers=True if cfg.hardware.num_workers > 0 else False)
    val_loader = DataLoader(val_ds, batch_size=cfg.deepspeed.train_micro_batch_size_per_gpu,
                            sampler=val_sampler, collate_fn=collate,
                            num_workers=cfg.hardware.num_workers, pin_memory=cfg.hardware.pin_memory,
                            prefetch_factor=2, persistent_workers=True if cfg.hardware.num_workers > 0 else False)
    test_loader = DataLoader(test_ds, batch_size=cfg.deepspeed.train_micro_batch_size_per_gpu,
                             sampler=test_sampler, collate_fn=collate,
                             num_workers=cfg.hardware.num_workers, pin_memory=cfg.hardware.pin_memory,
                             prefetch_factor=2, persistent_workers=True if cfg.hardware.num_workers > 0 else False)

    # ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸ ë° ì¶œë ¥
    if local_rank == 0:
        print(f"ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸°:")
        print(f"   Train: {len(train_ds):,}ê°œ ({len(train_loader):,} ë°°ì¹˜)")
        print(f"   Validation: {len(val_ds):,}ê°œ ({len(val_loader):,} ë°°ì¹˜)")
        print(f"   Test: {len(test_ds):,}ê°œ ({len(test_loader):,} ë°°ì¹˜)")

    # num_classes ë°˜í™˜ (ë©”íƒ€ë°ì´í„°ì—ì„œ ì½ê¸°)
    with open(os.path.join(arrow_dir, "meta.json")) as f:
        meta = json.load(f)
        num_classes = meta["num_classes"]
        if local_rank == 0 and "pkl_checksum" in meta:
            print(f"ğŸ“‹ ë°ì´í„°ì…‹ ë©”íƒ€ì •ë³´:")
            print(f"   ì›ë³¸ PKL: {meta.get('pkl_path', 'N/A')}")
            print(f"   ì²´í¬ì„¬: {meta.get('pkl_checksum', 'N/A')[:8]}...")
            print(f"   í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
    return train_loader, val_loader, test_loader, num_classes, tok

# í–¥ìƒëœ í‰ê°€ í•¨ìˆ˜ (MetricTracker í™œìš©)
def evaluate_model_comprehensive(model_engine, eval_dataloader, local_rank=0, metric_tracker=None, prefix=""):
    """ì¢…í•©ì ì¸ ëª¨ë¸ í‰ê°€ (loss, accuracy, f1, precision, recall)"""
    model_engine.eval()
    total_loss = 0
    all_predictions = []
    all_labels = []
    
    # MetricTrackerê°€ ì—†ìœ¼ë©´ ì„ì‹œ ìƒì„±
    if metric_tracker is None:
        metric_tracker = MetricTracker(local_rank)
    
    eval_start_time = time.time()
    
    with torch.no_grad():
        for batch in tqdm(eval_dataloader, desc="Evaluating", disable=local_rank != 0):
            input_ids = batch['input_ids'].to(local_rank)
            attention_mask = batch['attention_mask'].to(local_rank)
            labels = batch['labels'].to(local_rank)
            
            outputs = model_engine(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            predictions = torch.argmax(outputs.logits, dim=-1)
            
            total_loss += loss.item()
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    eval_time = time.time() - eval_start_time
    
    # MetricTrackerë¥¼ ì‚¬ìš©í•´ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ë¡œê¹…
    metrics = metric_tracker.calculate_and_log(
        predictions=np.array(all_predictions),
        labels=np.array(all_labels),
        prefix=prefix
    )
    
    # ì¶”ê°€ ë©”íŠ¸ë¦­
    metrics.update({
        f'{prefix}loss': total_loss / len(eval_dataloader),
        f'{prefix}eval_samples': len(all_predictions),
        f'{prefix}eval_time_sec': eval_time,
        f'{prefix}eval_samples_per_sec': len(all_predictions) / eval_time if eval_time > 0 else 0
    })
    
    return metrics

# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
def evaluate_model(model_engine, eval_dataloader):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í‰ê°€ í•¨ìˆ˜"""
    return evaluate_model_comprehensive(model_engine, eval_dataloader, local_rank)

# ë©”íƒ€ë°ì´í„° ìƒì„± í•¨ìˆ˜ ì¶”ê°€
def save_model_metadata(save_dir: str, model, tokenizer, config, num_classes: int):
    """ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì €ì¥"""
    metadata = {
        "model_info": {
            "base_model_name": config.model.name,
            "num_classes": num_classes,
            "torch_dtype": config.model.torch_dtype,
            "model_type": "sequence_classification",
            "peft_type": "LoRA",
            "created_at": datetime.now().isoformat()
        },
        "lora_config": OmegaConf.to_container(config.lora),
        "data_info": {
            "max_length": config.data.max_length,
            "padding": config.data.padding,
            "truncation": config.data.truncation,
            "extract_ratio": config.data.extract_ratio,
            "dataset_path": config.data.dataset_all_path
        },
        "tokenizer_info": {
            "vocab_size": tokenizer.vocab_size,
            "pad_token_id": tokenizer.pad_token_id,
            "eos_token_id": tokenizer.eos_token_id
        },
        "training_config": {
            "epochs": config.training.epochs,
            "batch_size": config.deepspeed.train_micro_batch_size_per_gpu,
            "learning_rate": config.deepspeed.optimizer.params.lr,
            "weight_decay": config.deepspeed.optimizer.params.weight_decay
        }
    }
    
    metadata_path = os.path.join(save_dir, "model_metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    return metadata_path

# save_company_scaling_stats í•¨ìˆ˜ ì‚­ì œë¨ - ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ

def save_dataset_metadata_once(arrow_dir: str, checkpoint_root_dir: str, local_rank: int = 0):
    """ì „ì²´ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„°ë¥¼ checkpoints í´ë”ì— í•œ ë²ˆë§Œ ì €ì¥"""
    if local_rank != 0:
        return None
    
    try:
        # Arrow ë””ë ‰í† ë¦¬ì—ì„œ ì „ì²´ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì½ê¸°
        full_metadata_path = os.path.join(arrow_dir, "dataset_full_metadata.json")
        
        if not os.path.exists(full_metadata_path):
            print(f"âš ï¸ ì „ì²´ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_metadata_path}")
            return None
        
        # ë©”íƒ€ë°ì´í„° ì½ê¸°
        with open(full_metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # ì €ì¥ ì‹œê°„ ì¶”ê°€
        metadata['saved_at'] = datetime.now().isoformat()
        
        # checkpoints í´ë” ë°”ë¡œ ì•„ë˜ì— ì €ì¥
        dataset_metadata_path = os.path.join(checkpoint_root_dir, "dataset_metadata.json")
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë®ì–´ì“°ê¸°
        with open(dataset_metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"   âœ… ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ì €ì¥: checkpoints/dataset_metadata.json")
        
        # ë©”íƒ€ë°ì´í„° ìš”ì•½ ì¶œë ¥
        print(f"   ğŸ“‹ ë©”íƒ€ë°ì´í„° ìš”ì•½:")
        print(f"      - num_classes: {metadata.get('num_classes', 'N/A')}")
        print(f"      - total_samples: {metadata.get('total_samples', 'N/A')}")
        print(f"      - target_column: {metadata.get('target_column', 'N/A')}")
        print(f"      - feature_columns ìˆ˜: {len(metadata.get('feature_columns', []))}")
        
        # company_scaling_statsëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        
        return dataset_metadata_path
        
    except Exception as e:
        print(f"   âš ï¸ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# ==================== ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ í•¨ìˆ˜ ====================

def find_latest_checkpoint(checkpoint_dir: Path, local_rank: int = 0) -> tuple[str, str, int]:
    """
    DeepSpeed latest íŒŒì¼ì„ í™œìš©í•˜ì—¬ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
    
    Returns:
        (checkpoint_dir, tag, epoch_number)
    """
    if not checkpoint_dir.exists():
        if local_rank == 0:
            logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {checkpoint_dir}")
        return None, None, 0
    
    # DeepSpeed latest íŒŒì¼ í™•ì¸ (DeepSpeedê°€ ìë™ ìƒì„±)
    latest_file = checkpoint_dir / "latest"
    if latest_file.exists():
        with open(latest_file, 'r') as f:
            latest_tag = f.read().strip()
            if local_rank == 0:
                logger.info(f"âœ… DeepSpeed latest íŒŒì¼ì—ì„œ íƒœê·¸ ë°œê²¬: {latest_tag}")
            
            # epoch ë²ˆí˜¸ ì¶”ì¶œ
            epoch_num = 0
            if "epoch_" in latest_tag:
                try:
                    epoch_num = int(latest_tag.split("epoch_")[1].split("_")[0])
                except:
                    epoch_num = int(latest_tag.split("_")[-1])
            
            return str(checkpoint_dir), latest_tag, epoch_num
    
    # latest íŒŒì¼ì´ ì—†ìœ¼ë©´ epoch_XX íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰
    epoch_dirs = sorted(checkpoint_dir.glob("epoch_*"), 
                       key=lambda x: int(x.name.split("_")[1]))
    
    if epoch_dirs:
        latest_dir = epoch_dirs[-1]
        tag = latest_dir.name
        epoch_num = int(tag.split("_")[1])
        
        if local_rank == 0:
            logger.info(f"âœ… ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {tag} (epoch {epoch_num})")
        
        return str(checkpoint_dir), tag, epoch_num
    
    if local_rank == 0:
        logger.info("ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    return None, None, 0


def load_checkpoint_deepspeed(model_engine, scheduler, checkpoint_dir: str, tag: str = None, local_rank: int = 0):
    """
    DeepSpeed ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ë‚´ì¥ ë©”ì†Œë“œ ìµœëŒ€ í™œìš©)
    
    Args:
        model_engine: DeepSpeed model engine
        scheduler: Learning rate scheduler
        checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        tag: ì²´í¬í¬ì¸íŠ¸ íƒœê·¸ (Noneì´ë©´ latest ì‚¬ìš©)
        local_rank: í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ rank
    
    Returns:
        (client_state, start_epoch, resume_run_id)
    """
    try:
        # DeepSpeed load_checkpoint í˜¸ì¶œ
        # tag=Noneì´ë©´ DeepSpeedê°€ ìë™ìœ¼ë¡œ latest íŒŒì¼ì„ ì½ì–´ì„œ ì²˜ë¦¬
        load_path, client_state = model_engine.load_checkpoint(
            checkpoint_dir,
            tag=tag,
            load_optimizer_states=True,
            load_lr_scheduler_states=True,  # DeepSpeedê°€ lr_schedulerë„ ë¡œë“œ
            load_module_strict=True
        )
        
        if local_rank == 0:
            actual_tag = tag if tag else "latest"
            print(f"âœ… DeepSpeed ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ (tag: {actual_tag})")
            print(f"   ë¡œë“œ ê²½ë¡œ: {load_path}")
            
            # DeepSpeed 0.14.4ì—ì„œëŠ” client_stateê°€ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ë¨
            if client_state:
                print(f"   Client state íƒ€ì…: {type(client_state)}")
                if isinstance(client_state, dict):
                    print(f"   Client state keys: {list(client_state.keys())}")
        
        # client_stateì—ì„œ ì •ë³´ ì¶”ì¶œ
        start_epoch = 0
        resume_run_id = None
        
        if client_state and isinstance(client_state, dict):
            # ì—í­ ì •ë³´
            if 'epoch' in client_state:
                start_epoch = client_state['epoch']
                print(f"   ğŸ“ ì—í­ {start_epoch} ì™„ë£Œë¨, ì—í­ {start_epoch + 1}ë¶€í„° ì¬ê°œ") if local_rank == 0 else None
            
            # MLflow run_id
            if 'mlflow_run_id' in client_state:
                resume_run_id = client_state['mlflow_run_id']
                print(f"   ğŸƒ MLflow run ID: {resume_run_id}") if local_rank == 0 else None
            
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì¶œë ¥
            if local_rank == 0:
                for key in ['train_loss', 'val_accuracy', 'val_loss', 'timestamp', 'num_classes']:
                    if key in client_state:
                        print(f"   ğŸ“Š {key}: {client_state[key]}")
        else:
            print("âš ï¸ client_stateê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜ˆìƒëœ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.") if local_rank == 0 else None
        
        return client_state, start_epoch, resume_run_id
        
    except Exception as e:
        if local_rank == 0:
            print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            print(f"   ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ: {checkpoint_dir}")
            print(f"   íƒœê·¸: {tag}")
            if "size mismatch" in str(e):
                print(f"âš ï¸ í´ë˜ìŠ¤ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(f"   ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ì‹œ í•™ìŠµí•˜ê±°ë‚˜ ë™ì¼í•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return None, 0, None


# ë©”ì¸ í•¨ìˆ˜
def main():
    # ì¸ìˆ˜ íŒŒì‹± (MLflow í”„ë¡œì íŠ¸ í˜¸í™˜ì„±)
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="conf/experiment.yaml")
    parser.add_argument("--local_rank", type=int, default=0)
    parser.add_argument("--checkpoint_path", type=str, default="", help="DeepSpeed ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ìë™ í•™ìŠµ ì¬ê°œ)")
    parser.add_argument("--resume_from_checkpoint", type=str, default="", help="ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (DeepSpeed ëŸ°ì²˜ í˜¸í™˜)")
    parser.add_argument("--checkpoint_tag", type=str, default="", help="ì²´í¬í¬ì¸íŠ¸ íƒœê·¸ (epoch_N ë˜ëŠ” latest)")
    parser.add_argument("--mlflow_run_id", type=str, default="", help="MLflow run ID ì¬ê°œ (í˜¸í™˜ì„±ìš©)")
    parser.add_argument("--run_id", type=str, default="", help="MLflow run ID ì¬ê°œ (DeepSpeed ì¸ììš©)")
    
    # MLflow í”„ë¡œì íŠ¸ íŒŒë¼ë¯¸í„°ë“¤ (YAML ì„¤ì • ì˜¤ë²„ë¼ì´ë“œìš©)
    parser.add_argument("--experiment_name", type=str, default="", help="ì‹¤í—˜ ì´ë¦„ (MLflowìš©)")
    parser.add_argument("--run_name", type=str, default="", help="ì‹¤í–‰ ì´ë¦„ (MLflowìš©)")
    parser.add_argument("--epochs", type=int, default=0, help="ì—í­ ìˆ˜ (0ì´ë©´ YAML ì„¤ì • ì‚¬ìš©)")
    parser.add_argument("--batch_size", type=int, default=0, help="ë°°ì¹˜ í¬ê¸° (0ì´ë©´ YAML ì„¤ì • ì‚¬ìš©)")
    parser.add_argument("--learning_rate", type=float, default=0.0, help="í•™ìŠµë¥  (0ì´ë©´ YAML ì„¤ì • ì‚¬ìš©)")
    parser.add_argument("--data_fraction", type=float, default=1.0, help="ë°ì´í„° ì‚¬ìš© ë¹„ìœ¨")
    parser.add_argument("--quick_test", action="store_true", help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    parser.add_argument("--mode", type=str, default="train", help="ì‹¤í–‰ ëª¨ë“œ (train/evaluate/etc)")
    parser.add_argument("--output_dir", type=str, default="", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--detailed_metrics", action="store_true", help="ìƒì„¸ ë©”íŠ¸ë¦­ ì¶œë ¥")
    
    args = parser.parse_args()
    
    if local_rank == 0:
        print(f"ğŸ¯ MLflow íŒŒë¼ë¯¸í„° ìˆ˜ì‹ :")
        print(f"   ì‹¤í—˜ ì´ë¦„: {args.experiment_name}")
        print(f"   ì‹¤í–‰ ì´ë¦„: {args.run_name}")
        print(f"   ì—í­: {args.epochs} (0ì´ë©´ YAML ì„¤ì • ì‚¬ìš©)")
        print(f"   ë°ì´í„° ë¹„ìœ¨: {args.data_fraction}")
        print(f"   ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: {args.quick_test}")
        print(f"   ëª¨ë“œ: {args.mode}")
        print(f"   ğŸ”‘ run_id: {args.run_id or args.mlflow_run_id or '(ì—†ìŒ)'}")
        print("")
    
    # DeepSpeed ì´ˆê¸°í™”
    deepspeed.init_distributed()
    
    # ì„¤ì • ë¡œë“œ
    config = OmegaConf.load(args.config)
    
    # ë””ë²„ê¹…: ì„¤ì • í™•ì¸
    if local_rank == 0:
        print(f"ğŸ” YAML ì„¤ì • ë¡œë“œ í™•ì¸:")
        print(f"   - config.data.extract_ratio: {config.data.extract_ratio}")
        print(f"   - config.training.epochs: {config.training.epochs}")
        print(f"   - config.deepspeed.train_micro_batch_size_per_gpu: {config.deepspeed.train_micro_batch_size_per_gpu}")
        print(f"   - config.deepspeed.optimizer.params.lr: {config.deepspeed.optimizer.params.lr}")
        print("")
    
    # í™˜ê²½ ì„¤ì •
    auto_setup_environment()
    
    # ==================== í†µí•© í´ë˜ìŠ¤ ì´ˆê¸°í™” ====================
    # ê²½ë¡œ ê´€ë¦¬ì ì´ˆê¸°í™”
    path_manager = PathManager(config, local_rank)
    path_manager.validate_data_path()
    
    # ë¡œê±° ì´ˆê¸°í™”
    logger = RankAwareLogger(local_rank)
    
    # GPU ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    gpu_monitor = GPUMonitor(local_rank)
    
    # ë©”íŠ¸ë¦­ íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
    metric_tracker = MetricTracker(local_rank)
    
    logger.info("âœ… í†µí•© ê´€ë¦¬ í´ë˜ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    gpu_monitor.log_memory("ì´ˆê¸°í™” í›„")
    
    # ğŸš€ ë‹¨ìˆœí™”ëœ ë°ì´í„° ë¡œë”© (40ì¤„ ì´ë‚´)
    train_dataloader, eval_dataloader, test_dataloader, num_classes, tokenizer = build_loaders(config)
    
    # Arrow ë””ë ‰í† ë¦¬ ê²½ë¡œ ì €ì¥ (ì—í­ë³„ ë©”íƒ€ë°ì´í„° ì €ì¥ìš©)
    arrow_dir = os.path.join(config.cache_dir, "hf_arrow")
    
    # ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì‹ ê·œ í•™ìŠµì‹œ ì‚¬ìš©)
    dataset_metadata = None
    dataset_metadata_path = os.path.join(arrow_dir, "dataset_full_metadata.json")
    if os.path.exists(dataset_metadata_path):
        try:
            with open(dataset_metadata_path, 'r') as f:
                dataset_metadata = json.load(f)
                if local_rank == 0:
                    print(f"ğŸ“Š ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ:")
                    print(f"   - ì „ì²´ ìƒ˜í”Œ ìˆ˜: {dataset_metadata.get('total_samples', 'N/A'):,}")
                    print(f"   - íƒ€ê²Ÿ ì»¬ëŸ¼: {dataset_metadata.get('target_column', 'N/A')}")
                    print(f"   - í”¼ì²˜ ì»¬ëŸ¼ ìˆ˜: {len(dataset_metadata.get('feature_columns', []))}")
                    if 'label_mapping' in dataset_metadata:
                        label_mapping = dataset_metadata['label_mapping']
                        print(f"   - ì‹¤ì œ í´ë˜ìŠ¤: {label_mapping.get('num_base_classes', 'N/A')}")
                        print(f"   - ë”ë¯¸ í´ë˜ìŠ¤: {label_mapping.get('num_dummy_classes', 'N/A')}")
        except Exception as e:
            if local_rank == 0:
                print(f"âš ï¸ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if local_rank == 0:
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: Train={len(train_dataloader.dataset)}, Val={len(eval_dataloader.dataset)}, Test={len(test_dataloader.dataset)}, Classes={num_classes}")
    
    # ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë° íƒœê·¸ ì²˜ë¦¬ (ë””ë²„ê¹… ê°•í™”)
    checkpoint_path = args.checkpoint_path or args.resume_from_checkpoint
    checkpoint_tag = args.checkpoint_tag
    start_epoch = 0
    # run_id íŒŒë¼ë¯¸í„° ìš°ì„  ì²˜ë¦¬ (DeepSpeed ì¸ì vs í˜¸í™˜ì„±)
    resume_run_id = args.run_id or args.mlflow_run_id
    checkpoint_num_classes = None  # ì²´í¬í¬ì¸íŠ¸ì˜ í´ë˜ìŠ¤ ìˆ˜
    is_resume_training = False  # í•™ìŠµ ì¬ê°œ ì—¬ë¶€ í”Œë˜ê·¸
    
    # ğŸ”§ MLflow artifacts ì „ì²´ ê²½ë¡œì—ì„œ íƒœê·¸ ìë™ ì¶”ì¶œ
    original_checkpoint_path = checkpoint_path  # ì›ë³¸ ê²½ë¡œ ë³´ì¡´
    if checkpoint_path and not checkpoint_tag:
        # MLflow artifacts ê²½ë¡œ íŒ¨í„´ ê°ì§€: .../artifacts/checkpoints/epoch_XX
        if "artifacts/checkpoints/" in checkpoint_path:
            # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ epoch_XX í˜•íƒœì¸ì§€ í™•ì¸
            path_parts = checkpoint_path.rstrip('/').split('/')
            last_part = path_parts[-1]
            if last_part.startswith('epoch_'):
                checkpoint_tag = last_part
                # ì›ë³¸ ê²½ë¡œëŠ” ë³´ì¡´í•˜ê³ , ë¡œë”© ë¡œì§ì—ì„œ ì²˜ë¦¬
                if local_rank == 0:
                    print(f"ğŸ” MLflow artifacts ê²½ë¡œ ìë™ ê°ì§€:")
                    print(f"   ì›ë³¸ ê²½ë¡œì—ì„œ íƒœê·¸ ì¶”ì¶œ: {last_part}")
                    print(f"   ì›ë³¸ ê²½ë¡œ ë³´ì¡´: {original_checkpoint_path}")
                    print(f"   ì¶”ì¶œëœ íƒœê·¸: {checkpoint_tag}")

    if local_rank == 0:
        print(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ ë§¤ê°œë³€ìˆ˜ í™•ì¸:")
        print(f"   checkpoint_path: {checkpoint_path}")
        print(f"   original_checkpoint_path: {original_checkpoint_path}")
        print(f"   checkpoint_tag: {checkpoint_tag}")
        print(f"   ì´ˆê¸° start_epoch: {start_epoch}")
        print(f"   ğŸ”‘ resume_run_id: {resume_run_id}")
    
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ìë™ ê°ì§€ ë° latest íŒŒì¼ í™œìš©
    if checkpoint_path and os.path.exists(checkpoint_path):
        if local_rank == 0:
            print(f"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë°œê²¬: {checkpoint_path}")
            
            # latest íŒŒì¼ í™•ì¸ ë° íƒœê·¸ ìë™ ì„¤ì • (íƒœê·¸ê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)
            latest_file = os.path.join(checkpoint_path, "latest")
            if not checkpoint_tag and os.path.exists(latest_file):
                try:
                    with open(latest_file, 'r') as f:
                        latest_tag = f.read().strip()
                        checkpoint_tag = latest_tag
                        print(f"ğŸ“Œ latest íŒŒì¼ì—ì„œ íƒœê·¸ ìë™ ê°ì§€: {latest_tag}")
                except Exception as e:
                    print(f"âš ï¸ latest íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # íƒœê·¸ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ latest ì‚¬ìš©
            if not checkpoint_tag:
                checkpoint_tag = "latest"
                
            print(f"ğŸ”„ íƒœê·¸ '{checkpoint_tag}'ë¡œ ìë™ í•™ìŠµ ì¬ê°œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            if resume_run_id:
                print(f"ğŸ”„ MLflow run_id '{resume_run_id}'ë¡œ ë¡œê·¸ ì¬ê°œ ì˜ˆì •")
            
            # ì²´í¬í¬ì¸íŠ¸ ë©”íƒ€ë°ì´í„° ì½ê¸° (model_metadata.jsonì—ì„œ ëª¨ë¸ ì •ë³´ í™•ì¸)
            try:
                # model_metadata.json íŒŒì¼ ê²½ë¡œ
                model_metadata_path = Path(checkpoint_path) / checkpoint_tag / "model_metadata.json"
                if model_metadata_path.exists():
                    with open(model_metadata_path, 'r') as f:
                        model_metadata = json.load(f)
                        # ëª¨ë¸ ì •ë³´ì—ì„œ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
                        if 'model_info' in model_metadata and 'num_classes' in model_metadata['model_info']:
                            checkpoint_num_classes = model_metadata['model_info']['num_classes']
                            print(f"ğŸ“Š model_metadata.jsonì—ì„œ í´ë˜ìŠ¤ ìˆ˜ ë°œê²¬: {checkpoint_num_classes}")
                            if checkpoint_num_classes != num_classes:
                                print(f"âš ï¸ í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜: ë°ì´í„°ì…‹={num_classes}, ì²´í¬í¬ì¸íŠ¸={checkpoint_num_classes}")
                                print(f"ğŸ”§ ì²´í¬í¬ì¸íŠ¸ì˜ í´ë˜ìŠ¤ ìˆ˜({checkpoint_num_classes})ë¡œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                                num_classes = checkpoint_num_classes
                            is_resume_training = True  # ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ë¯€ë¡œ ì¬ê°œ í•™ìŠµ
                            
                        
                        # ê¸°íƒ€ ëª¨ë¸ ì„¤ì • ì •ë³´ í™•ì¸
                        if 'data_info' in model_metadata:
                            print(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ì˜ ë°ì´í„° ì„¤ì •:")
                            print(f"   - max_length: {model_metadata['data_info'].get('max_length', 'N/A')}")
                            print(f"   - extract_ratio: {model_metadata['data_info'].get('extract_ratio', 'N/A')}")
                        
                        if 'tokenizer_info' in model_metadata:
                            print(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ì˜ í† í¬ë‚˜ì´ì € ì •ë³´:")
                            print(f"   - vocab_size: {model_metadata['tokenizer_info'].get('vocab_size', 'N/A')}")
                else:
                    print(f"âš ï¸ model_metadata.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_metadata_path}")
                    print(f"   ì‹ ê·œ í•™ìŠµìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ model_metadata.json ì½ê¸° ì‹¤íŒ¨: {e}")
                print(f"   ì‹ ê·œ í•™ìŠµìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ì¬í•™ìŠµì‹œ checkpoints í´ë”ì—ì„œ dataset_metadata.json ë¡œë“œ
    if is_resume_training and checkpoint_path:
        dataset_metadata_ckpt_path = os.path.join(checkpoint_path, "dataset_metadata.json")
        if os.path.exists(dataset_metadata_ckpt_path):
            try:
                with open(dataset_metadata_ckpt_path, 'r') as f:
                    dataset_metadata = json.load(f)
                    if local_rank == 0:
                        print(f"ğŸ“Š ì²´í¬í¬ì¸íŠ¸ í´ë”ì—ì„œ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                if local_rank == 0:
                    print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ì˜ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # í•™ìŠµ ëª¨ë“œ í™•ì¸ ë¡œê·¸
    if local_rank == 0:
        if is_resume_training:
            print(f"\nğŸ”„ === í•™ìŠµ ì¬ê°œ ëª¨ë“œ ===")
            print(f"   ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ: {checkpoint_path}")
            print(f"   ì²´í¬í¬ì¸íŠ¸ íƒœê·¸: {checkpoint_tag}")
            print(f"   í´ë˜ìŠ¤ ìˆ˜: {num_classes} (ì²´í¬í¬ì¸íŠ¸ ê¸°ì¤€)")
            print(f"   ë©”íƒ€ë°ì´í„° ì†ŒìŠ¤: checkpoints/dataset_metadata.json")
        else:
            print(f"\nğŸ†• === ì‹ ê·œ í•™ìŠµ ëª¨ë“œ ===")
            print(f"   ë°ì´í„°ì…‹ ê²½ë¡œ: {config.data.dataset_all_path}")
            print(f"   í´ë˜ìŠ¤ ìˆ˜: {num_classes} (ë°ì´í„°ì…‹ ê¸°ì¤€)")
            print(f"   ë©”íƒ€ë°ì´í„° ì†ŒìŠ¤: dataset_all.pkl")
        print(f"")
    
    # ëª¨ë¸ ìƒì„±
    # Qwen3ëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ pad_token_idë¥¼ ê°€ì§€ê³  ìˆìŒ (151643)
    model = AutoModelForSequenceClassification.from_pretrained(
        config.model.name,
        num_labels=num_classes,
        torch_dtype=getattr(torch, config.model.torch_dtype),
        trust_remote_code=config.model.trust_remote_code,
        pad_token_id=tokenizer.pad_token_id  # ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • (151643)
    )
    
    # ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ í† í° IDë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸
    if local_rank == 0:
        print(f"ğŸ“Œ ëª¨ë¸ í† í° ì„¤ì •:")
        print(f"   - Model pad_token_id: {model.config.pad_token_id}")
        print(f"   - Model eos_token_id: {model.config.eos_token_id if hasattr(model.config, 'eos_token_id') else 'N/A'}")
        if tokenizer.pad_token_id == tokenizer.eos_token_id:
            print("âš ï¸ ê²½ê³ : í† í¬ë‚˜ì´ì €ì—ì„œ PADì™€ EOSê°€ ë™ì¼í•©ë‹ˆë‹¤!")
        else:
            print("âœ… PADì™€ EOSê°€ ì˜¬ë°”ë¥´ê²Œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # PEFT ì ìš© (YAML ì•µì»¤ lora ì„¤ì • + ìŒìˆ˜ ì¸ë±ìŠ¤ ë³€í™˜)
    lora_dict = OmegaConf.to_container(config.lora)
    
    # layers_to_transformì˜ ìŒìˆ˜ ì¸ë±ìŠ¤ë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    if 'layers_to_transform' in lora_dict:
        total_layers = model.config.num_hidden_layers  # Qwen3-4B: 36
        idxs = []
        for i in lora_dict['layers_to_transform']:
            idxs.append(total_layers + i if i < 0 else i)
        lora_dict['layers_to_transform'] = sorted(set(idxs))
        
        if local_rank == 0:
            print(f"ğŸ¯ LoRA layers_to_transform ë³€í™˜: {config.lora.layers_to_transform} â†’ {lora_dict['layers_to_transform']}")
    
    lora_config = LoraConfig(**lora_dict)
    model = get_peft_model(model, lora_config)
    
    # ëª¨ë¸ ì„¤ì • ë™ê¸°í™”
    model.config.pad_token_id = tokenizer.pad_token_id
    if hasattr(model, 'base_model'):
        model.base_model.config.pad_token_id = tokenizer.pad_token_id
    
    # DeepSpeed ì„¤ì • ì¤€ë¹„ (warmup ì„¤ì • í¬í•¨)
    ds_config = OmegaConf.to_container(config.deepspeed, resolve=True)
    
    if local_rank == 0:
        print(f"ğŸ” ì´ˆê¸° ds_config scheduler ì„¤ì •:")
        if 'scheduler' in ds_config:
            print(f"   - scheduler type: {ds_config['scheduler'].get('type', 'N/A')}")
            print(f"   - scheduler params: {ds_config['scheduler'].get('params', {})}")
    
    # ì´ í›ˆë ¨ ìŠ¤í… ìˆ˜ ê³„ì‚° (warmup ë¹„ìœ¨ ì ìš©)
    total_steps = len(train_dataloader) * config.training.epochs
    warmup_steps = 0
    
    # warmup_steps ìë™ ê³„ì‚° ì²˜ë¦¬
    if hasattr(config.training, 'warmup_steps'):
        if config.training.warmup_steps == "auto":
            # "auto"ì¸ ê²½ìš° warmup_ratio ì‚¬ìš©
            if hasattr(config.training, 'warmup_ratio') and config.training.warmup_ratio > 0:
                warmup_steps = int(total_steps * config.training.warmup_ratio)
                if local_rank == 0:
                    print(f"ğŸ”¥ Warmup ìë™ ì„¤ì •: {warmup_steps} ìŠ¤í… (ì´ {total_steps} ìŠ¤í… ì¤‘ {config.training.warmup_ratio*100:.1f}%)")
        elif isinstance(config.training.warmup_steps, int) and config.training.warmup_steps > 0:
            # ì •ìˆ˜ë¡œ ì§ì ‘ ì§€ì •ëœ ê²½ìš°
            warmup_steps = config.training.warmup_steps
            if local_rank == 0:
                print(f"ğŸ”¥ Warmup ìˆ˜ë™ ì„¤ì •: {warmup_steps} ìŠ¤í…")
    elif hasattr(config.training, 'warmup_ratio') and config.training.warmup_ratio > 0:
        # warmup_stepsê°€ ì—†ê³  warmup_ratioë§Œ ìˆëŠ” ê²½ìš°
        warmup_steps = int(total_steps * config.training.warmup_ratio)
        if local_rank == 0:
            print(f"ğŸ”¥ Warmup ë¹„ìœ¨ ì„¤ì •: {warmup_steps} ìŠ¤í… (ì´ {total_steps} ìŠ¤í… ì¤‘ {config.training.warmup_ratio*100:.1f}%)")
    
    # scheduler ì„¤ì •ì— ë™ì  warmup ì ìš© (DeepSpeedëŠ” 'scheduler' í‚¤ ì‚¬ìš©)
    # warmup ì„¤ì •ê³¼ ê´€ê³„ì—†ì´ í•­ìƒ scheduler íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•¨
    if 'scheduler' in ds_config:
        if 'params' in ds_config['scheduler']:
            # learning_rate ê°€ì ¸ì˜¤ê¸° (optimizerì—ì„œ)
            learning_rate = ds_config.get('optimizer', {}).get('params', {}).get('lr', 1e-5)
            scheduler_type = ds_config['scheduler'].get('type', '')
            
            # ê¸°ë³¸ warmup_steps ì„¤ì • (warmupì´ ì—†ì–´ë„ schedulerëŠ” ì‘ë™í•´ì•¼ í•¨)
            if warmup_steps == 0:
                warmup_steps = int(total_steps * 0.1)  # ê¸°ë³¸ê°’: ì „ì²´ì˜ 10%
            
            # WarmupCosineLR íŒŒë¼ë¯¸í„° ì²˜ë¦¬
            if scheduler_type == "WarmupCosineLR":
                # total_num_steps ìë™ ì„¤ì •
                if ds_config['scheduler']['params'].get('total_num_steps') == "auto":
                    ds_config['scheduler']['params']['total_num_steps'] = total_steps
                
                # warmup_num_steps ìë™ ì„¤ì •
                if ds_config['scheduler']['params'].get('warmup_num_steps') == "auto":
                    ds_config['scheduler']['params']['warmup_num_steps'] = min(200, warmup_steps)
                
                # warmup_min_ratioì™€ cos_min_ratioëŠ” ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ
                # WarmupCosineLRì€ ratioë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ absolute lr ê°’ì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ
                
            # WarmupLR íŒŒë¼ë¯¸í„° ì²˜ë¦¬
            elif scheduler_type == "WarmupLR":
                if ds_config['scheduler']['params'].get('warmup_num_steps') == "auto":
                    ds_config['scheduler']['params']['warmup_num_steps'] = min(200, warmup_steps)
                
                if ds_config['scheduler']['params'].get('warmup_min_lr') == "auto":
                    ds_config['scheduler']['params']['warmup_min_lr'] = learning_rate * 0.1
                
                if ds_config['scheduler']['params'].get('warmup_max_lr') == "auto":
                    ds_config['scheduler']['params']['warmup_max_lr'] = learning_rate
            
            if local_rank == 0:
                lr_params = ds_config['scheduler']['params']
                actual_warmup = lr_params.get('warmup_num_steps', warmup_steps)
                actual_total = lr_params.get('total_num_steps', total_steps)
                
                if scheduler_type == "WarmupCosineLR":
                    warmup_min_ratio = lr_params.get('warmup_min_ratio', 0.1)
                    cos_min_ratio = lr_params.get('cos_min_ratio', 0.05)
                    print(f"   ğŸ“Š ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸:")
                    print(f"      - warmup_num_steps: {actual_warmup}")
                    print(f"      - total_num_steps: {actual_total}")
                    print(f"      - warmup_min_ratio: {warmup_min_ratio}")
                    print(f"      - cos_min_ratio: {cos_min_ratio}")
                    print(f"      - ì‹œì‘ LR: {learning_rate * warmup_min_ratio:.2e}")
                    print(f"      - ìµœëŒ€ LR: {learning_rate:.2e}")
                    print(f"      - ìµœì¢… LR: {learning_rate * cos_min_ratio:.2e}")
                else:
                    actual_min_lr = lr_params.get('warmup_min_lr', learning_rate * 0.1)
                    actual_max_lr = lr_params.get('warmup_max_lr', learning_rate)
                    print(f"   ğŸ“Š ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸:")
                    print(f"      - warmup_num_steps: {actual_warmup}")
                    print(f"      - warmup_min_lr: {actual_min_lr:.2e}")
                    print(f"      - warmup_max_lr: {actual_max_lr:.2e}")
                    print(f"      - total_num_steps: {actual_total}")
                    
            if local_rank == 0:
                print(f"ğŸ” ìµœì¢… ds_config scheduler ì„¤ì •:")
                print(f"   - scheduler params: {ds_config['scheduler'].get('params', {})}")
    
    # DeepSpeed ì´ˆê¸°í™” (ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì—†ì´)
    model_engine, optimizer, _, scheduler = deepspeed.initialize(
        model=model,
        config=ds_config,
        training_data=train_dataloader.dataset,
        collate_fn=train_dataloader.collate_fn
    )
    
    if local_rank == 0:
        print("âœ… DeepSpeed ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì „)")
        model.print_trainable_parameters()
        
        # Warmup ì„¤ì • ì •ë³´ ì¶œë ¥
        if hasattr(config.training, 'warmup_enabled') and config.training.warmup_enabled:
            # learning_rate ê°€ì ¸ì˜¤ê¸° (optimizerì—ì„œ)
            learning_rate = ds_config.get('optimizer', {}).get('params', {}).get('lr', 1e-5)
            
            print(f"ğŸ”¥ Warmup í™œì„±í™”:")
            print(f"   - Warmup ìŠ¤í…: {warmup_steps if 'warmup_steps' in locals() else 'N/A'}")
            print(f"   - Warmup ë¹„ìœ¨: {config.training.warmup_ratio*100:.1f}%" if hasattr(config.training, 'warmup_ratio') else "")
            print(f"   - Warmup íƒ€ì…: {ds_config.get('optimizer', {}).get('params', {}).get('warmup_type', 'N/A')}")
            if 'scheduler' in ds_config and 'params' in ds_config['scheduler']:
                lr_params = ds_config['scheduler']['params']
                scheduler_type = ds_config['scheduler'].get('type', '')
                
                if scheduler_type == "WarmupCosineLR":
                    # WarmupCosineLRì€ ratioë¥¼ ì‚¬ìš©
                    warmup_min_ratio = lr_params.get('warmup_min_ratio', 0.1)
                    cos_min_ratio = lr_params.get('cos_min_ratio', 0.05)
                    print(f"   - Warmup ì‹œì‘ LR: {learning_rate * warmup_min_ratio:.2e} (lr Ã— {warmup_min_ratio})")
                    print(f"   - Warmup ì¢…ë£Œ LR: {learning_rate:.2e} (ê¸°ë³¸ lr)")
                    print(f"   - Cosine ìµœì¢… LR: {learning_rate * cos_min_ratio:.2e} (lr Ã— {cos_min_ratio})")
                    print(f"   - Warmup ìŠ¤í…: {lr_params.get('warmup_num_steps', 'N/A')}")
                    print(f"   - ì´ ìŠ¤í…: {lr_params.get('total_num_steps', 'N/A')}")
                else:
                    # WarmupLR ë“± ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬
                    print(f"   - ìµœì†Œ í•™ìŠµë¥ : {lr_params.get('warmup_min_lr', 'N/A')}")
                    print(f"   - ìµœëŒ€ í•™ìŠµë¥ : {lr_params.get('warmup_max_lr', 'N/A')}")
        
        # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        memory_allocated = torch.cuda.memory_allocated() / 1e9
        print(f"ğŸ” DeepSpeed ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬: {memory_allocated:.1f}GB")
    
    # ğŸš€ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸ (MLflow/DeepSpeed ì´ˆê¸°í™” ì „)
    checkpoint_dir = path_manager.get('checkpoints')
    
    # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ë¯¸ë¦¬ í™•ì¸
    checkpoint_to_load = None
    tag_to_load = None
    
    if checkpoint_path or checkpoint_tag or args.resume_from_checkpoint:
        # ëª…ì‹œì  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        if not checkpoint_path:
            found_dir, found_tag, found_epoch = find_latest_checkpoint(checkpoint_dir, local_rank)
            if found_dir:
                checkpoint_to_load = found_dir
                tag_to_load = found_tag if checkpoint_tag == "latest" else checkpoint_tag
                start_epoch = found_epoch
                logger.info(f"ğŸ” ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {found_tag} (epoch {found_epoch})")
            else:
                logger.warning("ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            checkpoint_to_load = checkpoint_path
            tag_to_load = checkpoint_tag
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì „ì— resume_run_id ì´ˆê¸°í™”
    resume_run_id = None
    
    # MLflow ì„¤ì •ì€ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í›„ë¡œ ì´ë™
    run_id = None
    
    # ì¼ë‹¨ ì²´í¬í¬ì¸íŠ¸ ì •ë³´ë§Œ í™•ì¸ - MLflow ì‹œì‘ì€ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í›„ë¡œ ì´ë™
    if local_rank == 0:
        print("ğŸ” ì²´í¬í¬ì¸íŠ¸ ë¡œë”©ì„ ìœ„í•´ MLflow ì´ˆê¸°í™” ì§€ì—°...")
        
    
    # ëª¨ë“  rankì—ì„œ run_id ê³µìœ  (DeepSpeed ë¶„ì‚° í™˜ê²½)
    if torch.distributed.is_initialized():
        # run_idë¥¼ ëª¨ë“  rankì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
        if local_rank == 0:
            run_id_tensor = torch.tensor([hash(run_id) if run_id else 0], dtype=torch.long).cuda()
        else:
            run_id_tensor = torch.tensor([0], dtype=torch.long).cuda()
        torch.distributed.broadcast(run_id_tensor, 0)
        
        if local_rank == 0:
            print(f"ğŸ”„ MLflow run_id ëª¨ë“  rankì— ê³µìœ : {run_id}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ë³€ìˆ˜ ì´ˆê¸°í™”
    loaded_run_id = None
    
    # ğŸš€ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (DeepSpeed ì´ˆê¸°í™” í›„)
    if checkpoint_to_load and tag_to_load:
        logger.info(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œì‘: {checkpoint_to_load}, tag: {tag_to_load}")
        loaded_client_state, loaded_start_epoch, loaded_run_id = load_checkpoint_deepspeed(
            model_engine, 
            scheduler, 
            checkpoint_to_load, 
            tag_to_load, 
            local_rank
        )
        
        if loaded_client_state:
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œëœ ì •ë³´ ì‚¬ìš©
            start_epoch = loaded_start_epoch  # ì™„ë£Œëœ ì—í­ ë²ˆí˜¸
            if loaded_run_id and not resume_run_id:
                resume_run_id = loaded_run_id  # ì²´í¬í¬ì¸íŠ¸ì˜ run_id ì‚¬ìš©
            
            
            if local_rank == 0:
                print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ!")
                print(f"   - ì™„ë£Œëœ ì—í­: {start_epoch}")
                print(f"   - ë‹¤ìŒ ì—í­ë¶€í„° ì¬ê°œ: {start_epoch + 1}")
                print(f"   - MLflow run_id: {resume_run_id or 'N/A'}")
                if isinstance(loaded_client_state, dict):
                    print(f"   - í›ˆë ¨ ì†ì‹¤: {loaded_client_state.get('train_loss', 'N/A')}")
                    print(f"   - ê²€ì¦ ì •í™•ë„: {loaded_client_state.get('val_accuracy', 'N/A')}")
            
            is_resume_training = True
    
    # ğŸš€ MLflow ì´ˆê¸°í™” (ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í›„)
    if local_rank == 0:
        # MLflow í”„ë¡œì íŠ¸ í™˜ê²½ì—ì„œ ì´ë¯¸ runì´ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        active_run = mlflow.active_run()
        mlflow_run_id = os.environ.get('MLFLOW_RUN_ID')
        
        if active_run or mlflow_run_id:
            # ì´ë¯¸ MLflow í”„ë¡œì íŠ¸ì—ì„œ runì´ ì‹œì‘ë¨
            if active_run:
                print(f"ğŸ¯ MLflow í”„ë¡œì íŠ¸ run ì‚¬ìš©: {active_run.info.run_id}")
                print(f"   ì‹¤í—˜ ID: {active_run.info.experiment_id}")
                print(f"   ì‹¤í–‰ ì´ë¦„: {active_run.info.run_name}")
                run_id = active_run.info.run_id
            else:
                print(f"ğŸ¯ MLflow í”„ë¡œì íŠ¸ í™˜ê²½ ë³€ìˆ˜ ê°ì§€: {mlflow_run_id}")
                run_id = mlflow_run_id
        else:
            # CLI ì¸ìë¡œ ì „ë‹¬ë°›ì€ run_id í™•ì¸
            cli_run_id = args.run_id or args.mlflow_run_id
            if cli_run_id:
                resume_run_id = cli_run_id
                print(f"ğŸ¯ CLIì—ì„œ ì „ë‹¬ë°›ì€ run_id: {resume_run_id}")
            
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œí•œ run_idê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if loaded_run_id and not resume_run_id:
                resume_run_id = loaded_run_id
                print(f"ğŸ¯ ì²´í¬í¬ì¸íŠ¸ì—ì„œ MLflow run_id ì¶”ì¶œ: {resume_run_id}")
            
            # ì¼ë°˜ ëª¨ë“œì—ì„œ ìƒˆë¡œìš´ run ì‹œì‘ ë˜ëŠ” ê¸°ì¡´ run ì¬ê°œ
            if resume_run_id:
                try:
                    print(f"ğŸ”„ ê¸°ì¡´ MLflow run ì¬ê°œ ì‹œë„: {resume_run_id}")
                    # MLflow ì‹¤í—˜ ì„¤ì •
                    if args.experiment_name:
                        mlflow.set_experiment(args.experiment_name)
                    else:
                        mlflow.set_experiment("PEFT_DeepSpeed_Enhanced")
                    
                    # ê¸°ì¡´ runì— ì´ì–´ì„œ ê¸°ë¡
                    mlflow.start_run(run_id=resume_run_id)
                    print(f"âœ… ê¸°ì¡´ MLflow run ì¬ê°œ ì„±ê³µ: {resume_run_id}")
                    print(f"   â†’ ê¸°ì¡´ í´ë”ì— ì´ì–´ì„œ ì €ì¥ë©ë‹ˆë‹¤.")
                    run_id = resume_run_id
                except Exception as e:
                    print(f"âš ï¸ ê¸°ì¡´ MLflow run ì¬ê°œ ì‹¤íŒ¨: {e}")
                    print("ğŸ”„ ìƒˆë¡œìš´ runì„ ìƒì„±í•©ë‹ˆë‹¤...")
                    resume_run_id = None
            
            if not resume_run_id:
                # ìƒˆ MLflow run ì‹œì‘
                if args.run_name:
                    # ì‚¬ìš©ìê°€ run_nameì„ ì§€ì •í•œ ê²½ìš°
                    run_name = args.run_name
                    
                    # ì—í­ ì •ë³´ ë™ì  ì¶”ê°€ (run_nameì— :Epoch_ í¬í•¨ëœ ê²½ìš°)
                    if ":Epoch_" in run_name:
                        # ì‹œì‘ ì—í­ ê¸°ë°˜ìœ¼ë¡œ ì—í­ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
                        epoch_part = f"Epoch_{start_epoch + 1:02d}"
                        run_name = run_name.split(":Epoch_")[0] + f":{epoch_part}"
                    
                    print(f"ğŸ·ï¸ ì‚¬ìš©ì ì§€ì • run_name: {run_name}")
                    if checkpoint_path:
                        print(f"   (ì²´í¬í¬ì¸íŠ¸ ì¬ê°œ: {checkpoint_tag})")
                else:
                    # ê¸°ë³¸ run_name ìƒì„±
                    run_name = f"PEFT_DeepSpeed_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    if checkpoint_path:
                        run_name += f"_resume_from_{checkpoint_tag}"
                    
                    print(f"ğŸ·ï¸ ê¸°ë³¸ run_name ìƒì„±: {run_name}")
                
                mlflow.set_experiment("PEFT_DeepSpeed_Enhanced")
                mlflow.start_run(run_name=run_name)
                print(f"ğŸ¯ ìƒˆ MLflow run ì‹œì‘: {run_name}")
                run_id = mlflow.active_run().info.run_id
        
        # ì•ˆì „í•œ íŒŒë¼ë¯¸í„° ë¡œê¹… (rank 0 ì „ìš©)
        final_epochs = args.epochs if args.epochs > 0 else config.training.epochs
        final_batch_size = args.batch_size if args.batch_size > 0 else config.deepspeed.train_micro_batch_size_per_gpu
        final_learning_rate = args.learning_rate if args.learning_rate > 0.0 else config.deepspeed.optimizer.params.lr
        
        def safe_log_params(params_dict):
            """MLflow íŒŒë¼ë¯¸í„° ì¤‘ë³µ ë¡œê¹… ë°©ì§€ (rank 0 ì „ìš©)"""
            for key, value in params_dict.items():
                try:
                    mlflow.log_param(key, value)
                except Exception as e:
                    if "already logged" in str(e):
                        print(f"   âš ï¸ íŒŒë¼ë¯¸í„° '{key}' ì´ë¯¸ ë¡œê¹…ë¨ (ìŠ¤í‚µ)")
                    else:
                        print(f"   âŒ íŒŒë¼ë¯¸í„° '{key}' ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        # íŒŒë¼ë¯¸í„° ë¡œê¹… ì‹¤í–‰ (rank 0ë§Œ)
        try:
            # Warmup ê´€ë ¨ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
            warmup_params = {}
            if hasattr(config.training, 'warmup_enabled') and config.training.warmup_enabled:
                warmup_params.update({
                    "warmup_enabled": config.training.warmup_enabled,
                    "warmup_steps": warmup_steps if 'warmup_steps' in locals() else 0,
                    "warmup_ratio": config.training.warmup_ratio if hasattr(config.training, 'warmup_ratio') else 0.1,
                    "total_steps": total_steps if 'total_steps' in locals() else 0
                })
                
                # DeepSpeed ì„¤ì •ì—ì„œ warmup ì •ë³´ ì¶”ê°€
                if 'optimizer' in ds_config and 'params' in ds_config['optimizer']:
                    opt_params = ds_config['optimizer']['params']
                    warmup_params.update({
                        "warmup_type": opt_params.get('warmup_type', 'linear'),
                        "warmup_bias_lr": opt_params.get('warmup_bias_lr', 0.0),
                        "warmup_momentum": opt_params.get('warmup_momentum', 0.8)
                    })
                
                # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •ì—ì„œ warmup ì •ë³´ ì¶”ê°€
                if 'scheduler' in ds_config and 'params' in ds_config['scheduler']:
                    lr_params = ds_config['scheduler']['params']
                    scheduler_type = ds_config['scheduler'].get('type', 'WarmupCosineLR')
                    
                    if scheduler_type == "WarmupCosineLR":
                        warmup_params.update({
                            "warmup_min_ratio": lr_params.get('warmup_min_ratio', 0.1),
                            "cos_min_ratio": lr_params.get('cos_min_ratio', 0.05),
                            "scheduler_type": scheduler_type
                        })
                    else:
                        warmup_params.update({
                            "warmup_min_lr": lr_params.get('warmup_min_lr', 1e-6),
                            "warmup_max_lr": lr_params.get('warmup_max_lr', 2e-5),
                            "scheduler_type": scheduler_type
                        })
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ì™€ warmup íŒŒë¼ë¯¸í„° ë³‘í•©
            params_dict = {
                "model_name": config.model.name,
                "num_classes": num_classes,
                "epochs": final_epochs,
                "batch_size": final_batch_size,
                "learning_rate": final_learning_rate,
                "weight_decay": config.deepspeed.optimizer.params.weight_decay,
                "lora_r": config.lora.r,
                "lora_alpha": config.lora.lora_alpha,
                "lora_dropout": config.lora.lora_dropout,
                "extract_ratio": config.data.extract_ratio,
                "max_length": config.data.max_length,
                "torch_dtype": config.model.torch_dtype,
                "checkpoint_path": checkpoint_path or "",
                "checkpoint_tag": checkpoint_tag or "",
                "data_fraction": args.data_fraction,
                "quick_test": args.quick_test,
                "mode": args.mode,
                "resume_run_id": resume_run_id or "",
                "local_rank": local_rank,
                **warmup_params  # warmup íŒŒë¼ë¯¸í„° ì¶”ê°€
            }
            
            safe_log_params(params_dict)
            print(f"âœ… MLflow íŒŒë¼ë¯¸í„° ë¡œê¹… ì™„ë£Œ (warmup ì •ë³´ í¬í•¨)")
        except Exception as e:
            print(f"âš ï¸ MLflow íŒŒë¼ë¯¸í„° ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}")
    
    # YAML ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (ëª¨ë“  rankì—ì„œ ì‹¤í–‰)
    if args.epochs > 0:
        config.training.epochs = args.epochs
        if local_rank == 0:
            print(f"ğŸ”§ ì—í­ ì˜¤ë²„ë¼ì´ë“œ: {args.epochs}")
    
    if args.batch_size > 0:
        config.deepspeed.train_micro_batch_size_per_gpu = args.batch_size
        if local_rank == 0:
            print(f"ğŸ”§ ë°°ì¹˜ í¬ê¸° ì˜¤ë²„ë¼ì´ë“œ: {args.batch_size}")
    
    if args.learning_rate > 0.0:
        config.deepspeed.optimizer.params.lr = args.learning_rate
        if local_rank == 0:
            print(f"ğŸ”§ í•™ìŠµë¥  ì˜¤ë²„ë¼ì´ë“œ: {args.learning_rate}")
    
    if local_rank == 0:
        print(f"ğŸ“Š ìµœì¢… ì„¤ì •: ì—í­={config.training.epochs}, ë°°ì¹˜={config.deepspeed.train_micro_batch_size_per_gpu}, í•™ìŠµë¥ ={config.deepspeed.optimizer.params.lr}")
        if is_resume_training:
            print(f"ğŸ¯ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì—í­ {start_epoch} ì™„ë£Œ í™•ì¸")
            print(f"ğŸš€ í•™ìŠµ ì¬ê°œ: ì—í­ {start_epoch + 1}ë¶€í„° {config.training.epochs}ê¹Œì§€")
        else:
            print(f"ğŸ¯ ì‹œì‘ ì—í­: {start_epoch}")
            print(f"ğŸš€ í•™ìŠµ ë²”ìœ„: ì—í­ {start_epoch + 1}ë¶€í„° {config.training.epochs}ê¹Œì§€")
        print(f"ğŸ”‘ MLflow Run ID: {run_id}")
        print("")
    
    # ğŸ”¥ í›ˆë ¨ ë£¨í”„ ì‹œì‘
    # YAML ì„¤ì •ì—ì„œ progress_interval ê°€ì ¸ì˜¤ê¸°
    progress_interval = config.deepspeed.steps_per_print if hasattr(config.deepspeed, 'steps_per_print') else config.training.progress_interval
    
    logger.info(f"ğŸ“Š ì§„í–‰ë¥  ì¶œë ¥ ê°„ê²©: {progress_interval} ìŠ¤í…ë§ˆë‹¤")
    
    # GPU ëª¨ë‹ˆí„° ì´ˆê¸° ìƒíƒœ
    gpu_monitor.log_memory("í•™ìŠµ ì‹œì‘ ì „")
    
    for epoch in range(start_epoch, config.training.epochs):
        model_engine.train()
        
        # ë¶„ì‚° ìƒ˜í”ŒëŸ¬ ì—í­ ì„¤ì •
        if hasattr(train_dataloader.sampler, 'set_epoch'):
            train_dataloader.sampler.set_epoch(epoch)
        
        # ì§„í–‰ë¥ ë°” ì„¤ì • (ì¬ê°œ ì‹œ ì˜¬ë°”ë¥¸ ì—í­ í‘œì‹œ)
        current_epoch = epoch + 1
        if local_rank == 0:
            # ì¬ê°œ ì‹œì—ë„ ì •í™•í•œ ì§„í–‰ ìƒí™© í‘œì‹œ
            desc = f"Epoch {current_epoch}/{config.training.epochs}"
            if start_epoch > 0 and epoch == start_epoch:
                desc += " (resumed)"
            pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=desc)
        else:
            pbar = enumerate(train_dataloader)
        
        total_loss = 0
        num_batches = 0
        
        for step, batch in pbar:
            input_ids = batch['input_ids'].to(local_rank)
            attention_mask = batch['attention_mask'].to(local_rank)
            labels = batch['labels'].to(local_rank)
            
            outputs = model_engine(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            
            model_engine.backward(loss)
            model_engine.step()
            
            total_loss += loss.item()
            num_batches += 1
            
            # DeepSpeed ë‚´ì¥ ë©”íŠ¸ë¦­ê³¼ ì§„í–‰ë¥ ë°” ì—…ë°ì´íŠ¸ (rank 0ë§Œ)
            if local_rank == 0 and (step + 1) % progress_interval == 0:
                current_lr = model_engine.get_lr()[0] if hasattr(model_engine, 'get_lr') else 2e-5
                loss_val = loss.item()
                avg_loss = total_loss / num_batches
                # GPU ë©”ëª¨ë¦¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                gpu_stats = gpu_monitor.get_memory_stats()
                memory_allocated = gpu_stats.get('allocated_gb', 0)
                
                # í˜„ì¬ ê¸€ë¡œë²Œ ìŠ¤í… ê³„ì‚°
                global_step = epoch * len(train_dataloader) + step + 1
                
                # Warmup ìƒíƒœ í™•ì¸
                warmup_status = ""
                if hasattr(config.training, 'warmup_enabled') and config.training.warmup_enabled:
                    if 'warmup_steps' in locals() and warmup_steps > 0:
                        if global_step <= warmup_steps:
                            warmup_progress = (global_step / warmup_steps) * 100
                            warmup_status = f" [Warmup: {warmup_progress:.1f}%]"
                        else:
                            warmup_status = " [Warmup: Complete]"
                
                postfix = {
                    'loss': f'{loss_val:.4f}',
                    'avg_loss': f'{avg_loss:.4f}',
                    'lr': f'{current_lr:.2e}',
                    'mem': f'{memory_allocated:.1f}GB'
                }
                
                # warmup ìƒíƒœë¥¼ postfixì— ì¶”ê°€
                if warmup_status:
                    postfix['warmup'] = warmup_status
                
                pbar.set_postfix(postfix)
                
                # MLflow ì‹¤ì‹œê°„ ë¡œê¹… (rank 0 ì „ìš©)
                try:
                    metrics_dict = {
                        f'train_loss_step': loss.item(),
                        f'avg_train_loss': avg_loss,
                        f'learning_rate': current_lr,
                        f'memory_allocated_gb': memory_allocated,
                        f'global_step': global_step
                    }
                    
                    # Warmup ì •ë³´ ì¶”ê°€
                    if hasattr(config.training, 'warmup_enabled') and config.training.warmup_enabled:
                        if 'warmup_steps' in locals() and warmup_steps > 0:
                            warmup_progress = min(global_step / warmup_steps, 1.0)
                            metrics_dict.update({
                                'warmup_progress': warmup_progress,
                                'is_warmup_phase': 1 if global_step <= warmup_steps else 0
                            })
                    
                    mlflow.log_metrics(metrics_dict, step=global_step)
                except Exception as e:
                    print(f"âš ï¸ MLflow ì‹¤ì‹œê°„ ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        # ì—í­ í‰ê·  ì†ì‹¤ ê³„ì‚°
        avg_train_loss = total_loss / num_batches
        logger.info(f"ğŸ“Š ì—í­ {epoch + 1} í›ˆë ¨ í‰ê·  ì†ì‹¤: {avg_train_loss:.4f}")
        gpu_monitor.log_memory(f"ì—í­ {epoch + 1} ì¢…ë£Œ")
        
        # ì—í­ ì¢…ë£Œ í›„ í‰ê°€
        metrics = {'loss': avg_train_loss, 'accuracy': 0.0}
        
        if eval_dataloader:
            logger.info(f"ğŸ” ì—í­ {epoch + 1} í‰ê°€ ì‹œì‘...")
            
            metrics = evaluate_model_comprehensive(model_engine, eval_dataloader, local_rank, metric_tracker, prefix="eval_")
            
            if local_rank == 0:
                logger.info(f"ğŸ“ˆ ì—í­ {epoch + 1} í‰ê°€ ê²°ê³¼:")
                logger.info(f"  ğŸ“‰ Loss: {metrics['eval_loss']:.4f}")
                logger.info(f"  ğŸ¯ Accuracy: {metrics['eval_accuracy']:.4f} ({metrics['eval_accuracy']*100:.2f}%)")
                logger.info(f"  ğŸ“Š F1 (Weighted): {metrics['eval_f1_weighted']:.4f}")
                logger.info(f"  ğŸ“Š F1 (Macro): {metrics['eval_f1_macro']:.4f}")
                logger.info(f"  ğŸ“Š Precision: {metrics['eval_precision']:.4f}")
                logger.info(f"  ğŸ“Š Recall: {metrics['eval_recall']:.4f}")
                logger.info(f"  ğŸš€ Eval Speed: {metrics['eval_eval_samples_per_sec']:.2f} samples/sec")
                
                # MLflow ì¢…í•© ë¡œê¹… (rank 0 ì „ìš©)
                try:
                    mlflow.log_metrics({
                        f"train_loss": avg_train_loss,
                        f"eval_loss": metrics['eval_loss'],
                        f"eval_accuracy": metrics['eval_accuracy'],
                        f"eval_f1_weighted": metrics['eval_f1_weighted'], 
                        f"eval_f1_macro": metrics['eval_f1_macro'],
                        f"eval_precision_weighted": metrics['eval_precision'],
                        f"eval_recall_weighted": metrics['eval_recall'],
                        f"eval_samples_per_sec": metrics['eval_eval_samples_per_sec']
                    }, step=epoch + 1)
                    print(f"âœ… MLflow ì—í­ {epoch + 1} ë©”íŠ¸ë¦­ ë¡œê¹… ì™„ë£Œ")
                except Exception as e:
                    print(f"âš ï¸ MLflow ì¢…í•© ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        # ğŸš€ DeepSpeed ë‚´ì¥ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        # PathManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        ckpt_root = path_manager.get('checkpoints')
        
        # client_state ì¤€ë¹„ (MLflow run_id í¬í•¨)
        client_state = {
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_accuracy': metrics.get('eval_accuracy', 0.0),
            'val_loss': metrics.get('eval_loss', 0.0),
            'timestamp': datetime.now().isoformat(),
            'mlflow_run_id': run_id if run_id else "",  # MLflow run_id ì €ì¥
            'num_classes': num_classes,  # í´ë˜ìŠ¤ ìˆ˜ ì €ì¥ (í•™ìŠµ ì¬ê°œ ì‹œ í•„ìˆ˜)
            'local_rank': local_rank
        }
        
        # ì—í­ íƒœê·¸ ì„¤ì •
        epoch_tag = f"epoch_{epoch+1:02d}"
        
        logger.info(f"ğŸ’¾ DeepSpeed ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {ckpt_root}")
        logger.info(f"   íƒœê·¸: {epoch_tag}")
        logger.info(f"   MLflow Run ID: {run_id}")
        
        # DeepSpeed ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë£¨íŠ¸ ê²½ë¡œ + íƒœê·¸)
        model_engine.save_checkpoint(str(ckpt_root), tag=epoch_tag, client_state=client_state)
        
        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í„°ë¦¬ (DeepSpeedê°€ ìƒì„±í•œ ê²½ë¡œ)
        checkpoint_dir = ckpt_root / epoch_tag
        
        # lr_schedulerì™€ rng_state ìˆ˜ë™ ì €ì¥ (rank 0ë§Œ)
        try:
            if local_rank == 0 and scheduler is not None:
                scheduler_path = checkpoint_dir / "lr_scheduler.pt"
                torch.save(scheduler.state_dict(), scheduler_path)
                print(f"   âœ… lr_scheduler ì €ì¥: lr_scheduler.pt")
            
            if local_rank == 0:
                rng_state_path = checkpoint_dir / "rng_state.pth"
                rng_state = {
                    'python': random.getstate(),
                    'numpy': np.random.get_state(),
                    'torch': torch.get_rng_state(),
                    'cuda': torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None
                }
                torch.save(rng_state, rng_state_path)
                print(f"   âœ… RNG ìƒíƒœ ì €ì¥: rng_state.pth")
        except Exception as e:
            if local_rank == 0:
                print(f"   âš ï¸ lr_scheduler/RNG ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  rank ë™ê¸°í™” - ëª¨ë“  GPU ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
        if dist.is_initialized():
            dist.barrier()
        
        # rank-0ë§Œ ì¶”ê°€ ìƒíƒœ ì €ì¥ ë° MLflow artifacts ê°œì„ 
        if local_rank == 0:
            checkpoint_dir = ckpt_root / epoch_tag
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata_path = save_model_metadata(str(checkpoint_dir), model, tokenizer, config, num_classes)
            # company_scaling_stats ì‚­ì œë¨
            
            # ë°ì´í„°ì…‹ ì „ì²´ ë©”íƒ€ë°ì´í„° ì €ì¥ (checkpoints í´ë”ì— í•œ ë²ˆë§Œ)
            if epoch == 0:  # ì²« ë²ˆì§¸ ì—í­ì—ì„œë§Œ ì €ì¥
                dataset_metadata_path = save_dataset_metadata_once(arrow_dir, str(ckpt_root), local_rank)
            
            # ğŸ”¥ DeepSpeed í˜¸í™˜ MLflow artifacts ì €ì¥ (rank 0 ì „ìš©)
            import shutil
            
            try:
                # 1. í˜„ì¬ ì—í­ í´ë” MLflow artifacts ì €ì¥
                mlflow.log_artifacts(str(checkpoint_dir), f"checkpoints/{epoch_tag}")
                
                # 2. latest íŒŒì¼ ìƒì„± ë° ì €ì¥
                latest_file = ckpt_root / "latest"
                latest_file.write_text(epoch_tag)
                mlflow.log_artifact(str(latest_file), "checkpoints")
                
                # 3. zero_to_fp32.py ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬ ë° ì €ì¥
                zero_to_fp32_src = ckpt_root / "zero_to_fp32.py"
                if zero_to_fp32_src.exists():
                    mlflow.log_artifact(str(zero_to_fp32_src), "checkpoints")
                
                # 4. ì²« ë²ˆì§¸ ì—í­ì—ì„œ dataset_metadata.jsonë„ MLflowì— ì €ì¥
                if epoch == 0:
                    dataset_metadata_file = ckpt_root / "dataset_metadata.json"
                    if dataset_metadata_file.exists():
                        mlflow.log_artifact(str(dataset_metadata_file), "checkpoints")
                        print(f"   âœ… MLflow dataset_metadata.json ì €ì¥: checkpoints/dataset_metadata.json")
                
                print(f"   âœ… MLflow artifacts ì €ì¥ ì™„ë£Œ: checkpoints/{epoch_tag}")
                print(f"   âœ… MLflow latest íŒŒì¼ ì €ì¥: checkpoints/latest -> {epoch_tag}")
                print(f"   âœ… MLflow zero_to_fp32.py ì €ì¥: checkpoints/zero_to_fp32.py")
                
            except Exception as e:
                print(f"   âš ï¸ MLflow artifacts ì €ì¥ ì‹¤íŒ¨: {e}")
                print(f"   ğŸ”„ ì²´í¬í¬ì¸íŠ¸ëŠ” ë¡œì»¬ì— ì €ì¥ë¨: {checkpoint_dir}")
    
    # ğŸ í•™ìŠµ ì™„ë£Œ í›„ Test ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€
    if local_rank == 0:
        print(f"\nğŸ í•™ìŠµ ì™„ë£Œ! Test ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
        print(f"   Test ë°ì´í„°: {len(test_dataloader.dataset):,}ê°œ ìƒ˜í”Œ, {len(test_dataloader):,}ê°œ ë°°ì¹˜")
    
    test_metrics = evaluate_model_comprehensive(model_engine, test_dataloader, local_rank, metric_tracker=metric_tracker, prefix="")
    
    if local_rank == 0:
        print(f"\nğŸ¯ ìµœì¢… Test í‰ê°€ ê²°ê³¼:")
        print(f"  ğŸ“‰ Test Loss: {test_metrics['loss']:.4f}")
        print(f"  ğŸ¯ Test Accuracy: {test_metrics['accuracy']:.4f} ({test_metrics['accuracy']*100:.2f}%)")
        print(f"  ğŸ“Š Test F1 (Weighted): {test_metrics['f1_weighted']:.4f}")
        print(f"  ğŸ“Š Test F1 (Macro): {test_metrics['f1_macro']:.4f}")
        print(f"  ğŸ“Š Test Precision (Weighted): {test_metrics['precision']:.4f}")
        print(f"  ğŸ“Š Test Recall (Weighted): {test_metrics['recall']:.4f}")
        print(f"  ğŸš€ Test Speed: {test_metrics['eval_samples_per_sec']:.2f} samples/sec")
        
        # MLflowì— Test ë©”íŠ¸ë¦­ ë¡œê¹… (rank 0 ì „ìš©)
        try:
            mlflow.log_metrics({
                "test_loss": test_metrics['loss'],
                "test_accuracy": test_metrics['accuracy'],
                "test_f1_weighted": test_metrics['f1_weighted'],
                "test_f1_macro": test_metrics['f1_macro'],
                "test_precision_weighted": test_metrics['precision'],
                "test_recall_weighted": test_metrics['recall'],
                "test_samples_per_sec": test_metrics['eval_samples_per_sec']
            })
            print("âœ… MLflow Test ë©”íŠ¸ë¦­ ë¡œê¹… ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ MLflow Test ë©”íŠ¸ë¦­ ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        try:
            mlflow.end_run()
            print("ğŸ‰ MLflow run ì¢…ë£Œ ë° í›ˆë ¨ ì™„ë£Œ!")
        except Exception as e:
            print(f"âš ï¸ MLflow run ì¢…ë£Œ ì‹¤íŒ¨: {e}")
            print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 